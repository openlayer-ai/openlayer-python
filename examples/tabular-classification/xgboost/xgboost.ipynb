{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef55abc9",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unboxai/examples-gallery/blob/main/tabular-classification/xgboost/xgboost.ipynb)\n",
    "\n",
    "\n",
    "# Tabular classification using XGBoost\n",
    "\n",
    "This notebook illustrates how XGBoostmodels can be upladed to the Unbox platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30085674",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427680f",
   "metadata": {},
   "source": [
    "## Importing the modules and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33179b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c06216",
   "metadata": {},
   "source": [
    "We have stored the dataset on the following S3 bucket. If, for some reason, you get an error reading the csv directly from it, feel free to copy and paste the URL in your browser and download the csv file. Alternatively, you can also find the dataset on [this Kaggle competition](https://www.kaggle.com/datasets/uciml/mushroom-classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ce311",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/tabular-classification/mushrooms.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_URL)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb79765",
   "metadata": {},
   "source": [
    "## Pre-processing the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_encode_one_hot(df, encoders):\n",
    "    \"\"\" Encodes categorical features using one-hot encoding. \"\"\"\n",
    "    df = df.copy(True)\n",
    "    df.reset_index(drop=True, inplace=True) # Causes NaNs otherwise\n",
    "    for feature, enc in encoders.items():\n",
    "        print(f\"encoding {feature}\")\n",
    "        enc_df = pd.DataFrame(enc.transform(df[[feature]]).toarray(), columns=enc.get_feature_names([feature]))\n",
    "        df = df.join(enc_df)\n",
    "        df = df.drop(columns=feature)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98422ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder_dict(df, categorical_feature_names):\n",
    "    \"\"\" Creates encoders for each of the categorical features. \n",
    "        The predict function will need these encoders. \n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    encoders = {}\n",
    "    for feature in categorical_feature_names:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        enc.fit(df[[feature]])\n",
    "        encoders[feature] = enc\n",
    "    return encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53428eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing class names with 0 and 1\n",
    "class_map = {\"e\": 0, \"p\": 1}\n",
    "\n",
    "X, y = df.loc[:, df.columns != \"class\"], df[[\"class\"]].replace(class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bad7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = create_encoder_dict(X, list(X.columns))\n",
    "\n",
    "X_enc_one_hot = data_encode_one_hot(X, encoders)\n",
    "X_enc_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a2c27",
   "metadata": {},
   "source": [
    "## Splitting the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176147d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "x_train_one_hot = data_encode_one_hot(x_train, encoders)\n",
    "x_val_one_hot = data_encode_one_hot(x_val, encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2a7f13",
   "metadata": {},
   "source": [
    "## Training and evaluating the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940adbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using XGBoost data format\n",
    "dtrain = xgb.DMatrix(x_train_one_hot, label=y_train)\n",
    "dval = xgb.DMatrix(x_val_one_hot, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee882b61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param = {'max_depth':2, 'eta':1, 'objective':'binary:logistic' }\n",
    "num_round = 2\n",
    "\n",
    "xgboost_model = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f603d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = xgboost_model.predict(dval)\n",
    "labels = dval.get_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6787f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"error rate=%f\"\n",
    "    % (\n",
    "        sum(1 for i in range(len(preds)) if int(preds[i] > 0.5) != labels[i])\n",
    "        / float(len(preds))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c514e1",
   "metadata": {},
   "source": [
    "## Unbox part!\n",
    "\n",
    "### Instantiating the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a38cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unboxapi\n",
    "\n",
    "client = unboxapi.UnboxClient(\"YOUR_API_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4031585",
   "metadata": {},
   "source": [
    "### Creating a project on the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5562a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unboxapi.tasks import TaskType\n",
    "\n",
    "project = client.create_project(name=\"XGBoost project\", \n",
    "                                task_type=TaskType.TabularClassification,\n",
    "                                description=\"Evaluation of ML approaches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db90bf9",
   "metadata": {},
   "source": [
    "### Uploading the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7355e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the ground truths to the ordinal dataset for Unbox\n",
    "x_val['class'] = y_val.values\n",
    "x_train['class'] = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some important parameters\n",
    "class_names = [\"e\", \"p\"]  # the classes on the dataset\n",
    "feature_names = list(X.columns)  # feature names in the un-processed dataset\n",
    "categorical_feature_names = feature_names # all features are categorical in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = project.add_dataframe(\n",
    "    df=x_val,\n",
    "    class_names=class_names,\n",
    "    label_column_name='class',\n",
    "    commit_message='this is my mushroom dataset',\n",
    "    feature_names=feature_names,\n",
    "    categorical_feature_names=categorical_feature_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da0afb",
   "metadata": {},
   "source": [
    "### Uploading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe9352",
   "metadata": {},
   "source": [
    "First, it is important to create a `predict_proba` function, which is how Unbox interacts with your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(model, input_features: np.ndarray, col_names, one_hot_encoder, encoders):\n",
    "    \"\"\"Convert the raw input_features into one-hot encoded features\n",
    "    using our one hot encoder and each feature's encoder. \"\"\"\n",
    "    # Encoding the features using the encoders\n",
    "    df = pd.DataFrame(input_features, columns=col_names)\n",
    "    encoded_df = one_hot_encoder(df, encoders)\n",
    "    \n",
    "    # Converting the data to the XGBoost data format\n",
    "    data_xgb = xgb.DMatrix(encoded_df)\n",
    "    \n",
    "    # Making the predictions with the model\n",
    "    preds = model.predict(data_xgb)\n",
    "    \n",
    "    # Post-processing the predictions to the format Unbox expects\n",
    "    preds_proba = [[1 - p, p] for p in preds]\n",
    "    return np.array(preds_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50297977",
   "metadata": {},
   "source": [
    "Let's test the `predict_proba` function to make sure the input-output format is consistent with what Unbox expects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674147b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba(xgboost_model, x_val[:3][feature_names].to_numpy(), feature_names, data_encode_one_hot, encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe506e",
   "metadata": {},
   "source": [
    "Now, we can upload the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace580e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unboxapi.models import ModelType\n",
    "\n",
    "model = project.add_model(\n",
    "    function=predict_proba, \n",
    "    model=xgboost_model,\n",
    "    model_type=ModelType.xgboost,\n",
    "    class_names=class_names,\n",
    "    name='XGBoost Classifier',\n",
    "    commit_message='this is my mushrooms classification model',\n",
    "    feature_names=feature_names,\n",
    "    train_sample_df=x_train[:3000],\n",
    "    train_sample_label_column_name='class',\n",
    "    requirements_txt_file='requirements.txt',\n",
    "    categorical_feature_names=categorical_feature_names,\n",
    "    col_names=feature_names,\n",
    "    one_hot_encoder=data_encode_one_hot,\n",
    "    encoders=encoders,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32a47b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
