{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16240e7",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unboxai/examples-gallery/blob/main/tabular-classification/documentation-tutorial/tabular_tutorial_part_2.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee3517d",
   "metadata": {},
   "source": [
    "# Welcome to the Unbox tabular tutorial - Part 2\n",
    "\n",
    "You should use this notebook together with the final part of the [**tabular tutorial**](https://docs.unbox.ai/docs/uploading-your-first-model-and-dataset) from our documentation. This is where we solve the identified issue affecting the first version of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3262f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -e \"requirements.txt\" ]; then\n",
    "    curl \"https://raw.githubusercontent.com/unboxai/examples-gallery/main/tabular-classification/documentation-tutorial/requirements.txt\" --output \"requirements.txt\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78577a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c1d74f",
   "metadata": {},
   "source": [
    "## 1. Loading the original training set\n",
    "\n",
    "First, let's import the libraries we need and load the churn training set. We will then confirm the issue we have identified during the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e633540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775b2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/tabular-classification/Churn+prediction/churn_train.csv\"\n",
    "VALIDATION_SET_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/tabular-classification/Churn+prediction/churn_val.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50e97690",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(TRAINING_SET_URL)\n",
    "val_set = pd.read_csv(VALIDATION_SET_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a2170",
   "metadata": {},
   "source": [
    "During the tutorial, we discovered that our model was having trouble predicting samples from female users. More specifically, from retained female users, which was causing an error class to be 5x larger than the other.\n",
    "\n",
    "We hypothesized that that was a symptom of that situation being underrepresented on the training set. This is indeed the case! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ffae7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender  Exited\n",
       "Female  0           20\n",
       "        1           80\n",
       "Male    0         3346\n",
       "        1          654\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.groupby([\"Gender\", \"Exited\"])[\"Exited\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906fbf18",
   "metadata": {},
   "source": [
    "Notice how there are only 100 samples from female users. Out of those, only 20 are from retained female users. On the other hand, male users make up ~97% of the dataset. It is clear that we need more data for female users to remove our model's bias!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06abb705",
   "metadata": {},
   "source": [
    "## 2. Augmenting the training set\n",
    "\n",
    "To augment our training set, we have gotten almost 5000 new labeled samples from production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b562a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_PROD_DATA_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/tabular-classification/Churn+prediction/churn_new_prod_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "080f075b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8274</td>\n",
       "      <td>15709643</td>\n",
       "      <td>Gray</td>\n",
       "      <td>675</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85901.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8277</td>\n",
       "      <td>15775131</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>580</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>142188.20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>128028.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8281</td>\n",
       "      <td>15745716</td>\n",
       "      <td>McGregor</td>\n",
       "      <td>706</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>117939.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8282</td>\n",
       "      <td>15598485</td>\n",
       "      <td>Pinto</td>\n",
       "      <td>567</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>28649.64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>95140.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8284</td>\n",
       "      <td>15754569</td>\n",
       "      <td>Pagnotto</td>\n",
       "      <td>664</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56562.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
       "0       8274    15709643      Gray          675    France   Male   32       1   \n",
       "1       8277    15775131  Bartlett          580     Spain   Male   32       9   \n",
       "2       8281    15745716  McGregor          706     Spain   Male   53       7   \n",
       "3       8282    15598485     Pinto          567     Spain   Male   40       8   \n",
       "4       8284    15754569  Pagnotto          664    France   Male   57       1   \n",
       "\n",
       "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0       0.00              3          1               0         85901.09   \n",
       "1  142188.20              2          0               1        128028.60   \n",
       "2       0.00              2          0               1        117939.17   \n",
       "3   28649.64              1          1               1         95140.62   \n",
       "4       0.00              2          1               1         56562.57   \n",
       "\n",
       "   Exited  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prod_data = pd.read_csv(NEW_PROD_DATA_URL)\n",
    "new_prod_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb8477",
   "metadata": {},
   "source": [
    "We are going to augment our training set with 3000 new samples from female users. Hopefully, now our training set is much more balanced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e17d8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_user_data = new_prod_data[new_prod_data[\"Gender\"] == \"Female\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cfdb549",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_new = pd.concat([training_set, female_user_data.iloc[:3000, :]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b14b334",
   "metadata": {},
   "source": [
    "## 3. Pre-process data and re-train the model\n",
    "\n",
    "Now it's time to pre-process the data again, to encode the categorical features and re-train our gradient boosting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "483253d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_set_new.iloc[:, 3:-1]\n",
    "y_train = training_set_new.iloc[:, -1]\n",
    "\n",
    "X_val = val_set.iloc[:, 3:-1]\n",
    "y_val = val_set.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e59be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_encode_one_hot(df, encoders):\n",
    "    \"\"\" Encodes categorical features using one-hot encoding. \"\"\"\n",
    "    df = df.copy(True)\n",
    "    df.reset_index(drop=True, inplace=True) # Causes NaNs otherwise\n",
    "    for feature, enc in encoders.items():\n",
    "        print(f\"encoding {feature}\")\n",
    "        enc_df = pd.DataFrame(enc.transform(df[[feature]]).toarray(), columns=enc.get_feature_names([feature]))\n",
    "        df = df.join(enc_df)\n",
    "        df = df.drop(columns=feature)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa3ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder_dict(df, categorical_feature_names):\n",
    "    \"\"\" Creates encoders for each of the categorical features. \n",
    "        The predict function will need these encoders. \n",
    "    \"\"\"\n",
    "    encoders = {}\n",
    "    for feature in categorical_feature_names:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        enc.fit(df[[feature]])\n",
    "        encoders[feature] = enc\n",
    "    return encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "702b88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the encoder dict for the categorical features (gender and geography)\n",
    "encoders = create_encoder_dict(X_train, ['Geography', 'Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90daf6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding Geography\n",
      "encoding Gender\n",
      "encoding Geography\n",
      "encoding Gender\n"
     ]
    }
   ],
   "source": [
    "# encoding the categorical features in our training and validation sets\n",
    "X_train_one_hot = data_encode_one_hot(X_train, encoders)\n",
    "X_val_one_hot = data_encode_one_hot(X_val, encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e122eaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model = GradientBoostingClassifier(random_state=42) \n",
    "sklearn_model.fit(X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1192f317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       795\n",
      "           1       0.75      0.58      0.65       205\n",
      "\n",
      "    accuracy                           0.87      1000\n",
      "   macro avg       0.82      0.76      0.79      1000\n",
      "weighted avg       0.87      0.87      0.87      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, sklearn_model.predict(X_val_one_hot)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969aed8",
   "metadata": {},
   "source": [
    "## 5. Unbox part -- have fun creating the next few cells!\n",
    "\n",
    "Now it's up to you! We will just compute a few important quantities and functions. \n",
    "\n",
    "Head back to the tutorial to see how you need to fill out the next few cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b70ae7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.values.tolist()\n",
    "categorical_feature_names = [\"Gender\", \"Geography\"]\n",
    "class_names = [\"Retained\", \"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a5d9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(model, input_features: np.ndarray, col_names, one_hot_encoder, encoders):\n",
    "    df = pd.DataFrame(input_features, columns=col_names)\n",
    "    encoded_df = one_hot_encoder(df, encoders)\n",
    "    return model.predict_proba(encoded_df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f3d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
