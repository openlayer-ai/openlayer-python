{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3647b33",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unboxai/examples-gallery/blob/main/tabular-classification/documentation-tutorial/tabular-tutorial-part-2.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee3517d",
   "metadata": {},
   "source": [
    "# Welcome to the Unbox tabular tutorial - Part 2\n",
    "\n",
    "You should use this notebook together with the final part of the [**tabular tutorial**](https://docs.unbox.ai/docs/uploading-your-first-model-and-dataset) from our documentation. This is where we solve the identified issue affecting the first version of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -e \"requirements.txt\" ]; then\n",
    "    curl \"https://raw.githubusercontent.com/unboxai/examples-gallery/main/tabular-classification/documentation-tutorial/requirements.txt\" --output \"requirements.txt\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78577a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c1d74f",
   "metadata": {},
   "source": [
    "## 1. Loading the original training set\n",
    "\n",
    "First, let's import the libraries we need and load the churn training set. We will then confirm the issue we have identified during the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e633540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/tabular-classification/Churn+prediction/churn_train.csv\"\n",
    "VALIDATION_SET_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/tabular-classification/Churn+prediction/churn_val.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e97690",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(TRAINING_SET_URL)\n",
    "val_set = pd.read_csv(VALIDATION_SET_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a2170",
   "metadata": {},
   "source": [
    "During the tutorial, we discovered that our model was having trouble predicting samples from female users. More specifically, from retained female users, which was causing an error class to be 5x larger than the other.\n",
    "\n",
    "We hypothesized that that was a symptom of that situation being underrepresented on the training set. This is indeed the case! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffae7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.groupby([\"Gender\", \"Exited\"])[\"Exited\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906fbf18",
   "metadata": {},
   "source": [
    "Notice how there are only 100 samples from female users. Out of those, only 20 are from retained female users. On the other hand, male users make up ~97% of the dataset. It is clear that we need more data for female users to remove our model's bias!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06abb705",
   "metadata": {},
   "source": [
    "## 2. Augmenting the training set\n",
    "\n",
    "To augment our training set, we have gotten almost 5000 new labeled samples from production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_PROD_DATA_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/tabular-classification/Churn+prediction/churn_new_prod_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prod_data = pd.read_csv(NEW_PROD_DATA_URL)\n",
    "new_prod_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb8477",
   "metadata": {},
   "source": [
    "We are going to augment our training set with 3000 new samples from female users. Hopefully, now our training set is much more balanced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_user_data = new_prod_data[new_prod_data[\"Gender\"] == \"Female\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfdb549",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_new = pd.concat([training_set, female_user_data.iloc[:3000, :]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b14b334",
   "metadata": {},
   "source": [
    "## 3. Pre-process data and re-train the model\n",
    "\n",
    "Now it's time to pre-process the data again, to encode the categorical features and re-train our gradient boosting classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483253d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_set_new.iloc[:, 3:-1]\n",
    "y_train = training_set_new.iloc[:, -1]\n",
    "\n",
    "X_val = val_set.iloc[:, 3:-1]\n",
    "y_val = val_set.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_encode_one_hot(df, encoders):\n",
    "    \"\"\" Encodes categorical features using one-hot encoding. \"\"\"\n",
    "    df = df.copy(True)\n",
    "    df.reset_index(drop=True, inplace=True) # Causes NaNs otherwise\n",
    "    for feature, enc in encoders.items():\n",
    "        print(f\"encoding {feature}\")\n",
    "        enc_df = pd.DataFrame(enc.transform(df[[feature]]).toarray(), columns=enc.get_feature_names([feature]))\n",
    "        df = df.join(enc_df)\n",
    "        df = df.drop(columns=feature)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa3ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder_dict(df, categorical_feature_names):\n",
    "    \"\"\" Creates encoders for each of the categorical features. \n",
    "        The predict function will need these encoders. \n",
    "    \"\"\"\n",
    "    encoders = {}\n",
    "    for feature in categorical_feature_names:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        enc.fit(df[[feature]])\n",
    "        encoders[feature] = enc\n",
    "    return encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the encoder dict for the categorical features (gender and geography)\n",
    "encoders = create_encoder_dict(X_train, ['Geography', 'Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90daf6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the categorical features in our training and validation sets\n",
    "X_train_one_hot = data_encode_one_hot(X_train, encoders)\n",
    "X_val_one_hot = data_encode_one_hot(X_val, encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model = GradientBoostingClassifier(random_state=42) \n",
    "sklearn_model.fit(X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1192f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, sklearn_model.predict(X_val_one_hot)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969aed8",
   "metadata": {},
   "source": [
    "## 5. Unbox part -- have fun creating the next few cells!\n",
    "\n",
    "Now it's up to you! We will just compute a few important quantities and functions. \n",
    "\n",
    "Head back to the tutorial to see how you need to fill out the next few cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ae7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.values.tolist()\n",
    "categorical_feature_names = [\"Gender\", \"Geography\"]\n",
    "class_names = [\"Retained\", \"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(model, input_features: np.ndarray, col_names, one_hot_encoder, encoders):\n",
    "    df = pd.DataFrame(input_features, columns=col_names)\n",
    "    encoded_df = one_hot_encoder(df, encoders)\n",
    "    return model.predict_proba(encoded_df.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the client and loading the project\n",
    "import unboxapi\n",
    "\n",
    "client = unboxapi.UnboxClient('YOUR_API_KEY_HERE')\n",
    "project = client.load_project(name='Churn prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47183813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading the model to the project\n",
    "from unboxapi.models import ModelType\n",
    "\n",
    "model = project.add_model(\n",
    "    name='Churn Classifier',\n",
    "    commit_message='Retrain on augmented training set with female users',\n",
    "    function=predict_proba, \n",
    "    model=sklearn_model,\n",
    "    model_type=ModelType.sklearn,\n",
    "    class_names=class_names,\n",
    "    feature_names=feature_names,\n",
    "    train_sample_df=training_set_new[:3000],\n",
    "    train_sample_label_column_name='Exited',\n",
    "    requirements_txt_file='requirements.txt',\n",
    "    categorical_feature_names=categorical_feature_names,\n",
    "    col_names=feature_names,\n",
    "    one_hot_encoder=data_encode_one_hot,\n",
    "    encoders=encoders,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b44ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
