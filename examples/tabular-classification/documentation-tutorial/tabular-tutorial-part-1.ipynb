{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f1b230",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unboxai/examples-gallery/blob/main/tabular-classification/documentation-tutorial/tabular-tutorial-part-1.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deda21b",
   "metadata": {},
   "source": [
    "# Welcome to the Unbox tabular tutorial - Part 1\n",
    "\n",
    "You should use this notebook together with the [**tabular tutorial**](https://docs.unbox.ai/docs/uploading-your-first-model-and-dataset) from our documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56758c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -e \"requirements.txt\" ]; then\n",
    "    curl \"https://raw.githubusercontent.com/unboxai/examples-gallery/main/tabular-classification/documentation-tutorial/requirements.txt\" --output \"requirements.txt\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7debb76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2b5430",
   "metadata": {},
   "source": [
    "## 1. Loading the dataset\n",
    "\n",
    "First, let's import the libraries we need and load the churn training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f69dcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcd7852",
   "metadata": {},
   "source": [
    "We have stored the dataset on the following S3 bucket. If, for some reason, you get an error reading the csv directly from it, feel free to copy and paste the URL in your browser and download the csv file. The churn dataset we use was constructed from the dataset from [this Kaggle competition](https://www.kaggle.com/competitions/churn-modelling/overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed8bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/tabular-classification/Churn+prediction/churn_train.csv\"\n",
    "VALIDATION_SET_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/tabular-classification/Churn+prediction/churn_val.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac811397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>15767821</td>\n",
       "      <td>Bearce</td>\n",
       "      <td>528</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80181.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography Gender  Age  Tenure  \\\n",
       "0          6    15574012       Chu          645     Spain   Male   44       8   \n",
       "1          7    15592531  Bartlett          822    France   Male   50       7   \n",
       "2          9    15792365        He          501    France   Male   44       4   \n",
       "3         10    15592389        H?          684    France   Male   27       2   \n",
       "4         11    15767821    Bearce          528    France   Male   31       6   \n",
       "\n",
       "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0  113755.78              2          1               0        149756.71   \n",
       "1       0.00              2          1               1         10062.80   \n",
       "2  142051.07              2          0               1         74940.50   \n",
       "3  134603.88              1          1               1         71725.73   \n",
       "4  102016.72              2          0               0         80181.12   \n",
       "\n",
       "   Exited  \n",
       "0       1  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading and having a look at the training set\n",
    "training_set = pd.read_csv(TRAINING_SET_URL)\n",
    "val_set = pd.read_csv(VALIDATION_SET_URL)\n",
    "\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b626945",
   "metadata": {},
   "source": [
    "The label we want to learn to predict is in the column `Exited`: retained users have a value of 0 while users that exited have a value of 1. Additionally, we **don't** want to use the `RowNumber`, `CurtomerId`, and `Surname` in our model, so we exclude these columns from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ccaafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_set.iloc[:, 3:-1]\n",
    "y_train = training_set.iloc[:, -1]\n",
    "\n",
    "X_val = val_set.iloc[:, 3:-1]\n",
    "y_val = val_set.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0206c2e",
   "metadata": {},
   "source": [
    "## 2. Pre-processing the data\n",
    "\n",
    "Notice from one of the previous cell's output that the users' genders and geographies are **categorical features**. Therefore, before feeding the data into the model, we need to encode them. Let's apply a **one-hot-encoding**, which is a common choice when dealing with categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29e71531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_encode_one_hot(df, encoders):\n",
    "    \"\"\" Encodes categorical features using one-hot encoding. \"\"\"\n",
    "    df = df.copy(True)\n",
    "    df.reset_index(drop=True, inplace=True) # Causes NaNs otherwise\n",
    "    for feature, enc in encoders.items():\n",
    "        print(f\"encoding {feature}\")\n",
    "        enc_df = pd.DataFrame(enc.transform(df[[feature]]).toarray(), columns=enc.get_feature_names([feature]))\n",
    "        df = df.join(enc_df)\n",
    "        df = df.drop(columns=feature)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3680efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder_dict(df, categorical_feature_names):\n",
    "    \"\"\" Creates encoders for each of the categorical features. \n",
    "        The predict function will need these encoders. \n",
    "    \"\"\"\n",
    "    encoders = {}\n",
    "    for feature in categorical_feature_names:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        enc.fit(df[[feature]])\n",
    "        encoders[feature] = enc\n",
    "    return encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fcfef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the encoder dict for the categorical features (gender and geography)\n",
    "encoders = create_encoder_dict(X_train, ['Geography', 'Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53491eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding Geography\n",
      "encoding Gender\n",
      "encoding Geography\n",
      "encoding Gender\n"
     ]
    }
   ],
   "source": [
    "# encoding the categorical features in our training and validation sets\n",
    "X_train_one_hot = data_encode_one_hot(X_train, encoders)\n",
    "X_val_one_hot = data_encode_one_hot(X_val, encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0f1a8",
   "metadata": {},
   "source": [
    "## 3. Training and evaluating our model\n",
    "\n",
    "We are going to train a gradient boosting classifier on the training data. Let's then check out what the model's performance is in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a981bc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model = GradientBoostingClassifier(random_state=42) \n",
    "sklearn_model.fit(X_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba829dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78       795\n",
      "           1       0.38      0.75      0.50       205\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.65      0.72      0.64      1000\n",
      "weighted avg       0.80      0.69      0.72      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, sklearn_model.predict(X_val_one_hot)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb702d1f",
   "metadata": {},
   "source": [
    "## 5. Unbox part!\n",
    "\n",
    "Now it's up to you! We will just compute a few important variables and concatenate the x and y, because Unbox expects a single dataframe with features and labels for the upload. \n",
    "\n",
    "Head back to the tutorial for an explanation of next few cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1682ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.values.tolist()\n",
    "categorical_feature_names = [\"Gender\", \"Geography\"]\n",
    "class_names = [\"Retained\", \"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d480f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.concat([X_train, y_train], axis=1)\n",
    "validation_set = pd.concat([X_val, y_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65964db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the client\n",
    "import unboxapi\n",
    "\n",
    "client = unboxapi.UnboxClient('YOUR_API_KEY_HERE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dee6250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the project\n",
    "from unboxapi.tasks import TaskType\n",
    "\n",
    "project = client.create_project(name=\"Churn prediction\",\n",
    "                               task_type=TaskType.TabularClassification,\n",
    "                               description=\"Evaluation of ML approaches to predict churn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c680e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading the dataset to the project\n",
    "dataset = project.add_dataframe(\n",
    "  df=validation_set,  \n",
    "  commit_message='churn validation set for October',\n",
    "  class_names=class_names,  \n",
    "  label_column_name='Exited',    \n",
    "  feature_names=feature_names,  \n",
    "  categorical_feature_names=categorical_feature_names,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b55095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model's predict probability function\n",
    "def predict_proba(model, input_features: np.ndarray, col_names: list, one_hot_encoder, encoders):\n",
    "    # Pre-processing the categorical features\n",
    "    df = pd.DataFrame(input_features, columns=col_names)\n",
    "    encoded_df = one_hot_encoder(df, encoders)\n",
    "    \n",
    "    # Getting the model's predictions\n",
    "    preds = model.predict_proba(encoded_df.to_numpy())\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d5cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploading the model to the project\n",
    "from unboxapi.models import ModelType\n",
    "\n",
    "model = project.add_model(\n",
    "    function=predict_proba, \n",
    "    model=sklearn_model,\n",
    "    model_type=ModelType.sklearn,\n",
    "    class_names=class_names,\n",
    "    name='Churn Classifier',\n",
    "    commit_message='this is my churn classification model',\n",
    "    feature_names=feature_names,\n",
    "    train_sample_df=training_set[:3000],\n",
    "    train_sample_label_column_name='Exited',\n",
    "    categorical_feature_names=categorical_feature_names,\n",
    "    requirements_txt_file='requirements.txt',\n",
    "    col_names=feature_names,\n",
    "    one_hot_encoder=data_encode_one_hot,\n",
    "    encoders=encoders,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a29256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
