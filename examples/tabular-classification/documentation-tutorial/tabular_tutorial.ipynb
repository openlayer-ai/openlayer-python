{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unboxai/examples-gallery/blob/main/tabular-classification/documentation-tutorial/tabular_tutorial.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDqSDHPas1IS"
   },
   "source": [
    "# Welcome to the Unbox tabular tutorial!\n",
    "\n",
    "We made our best to make it as simple as possible. You should use this notebook together with the [**tabular tutorial**](https://docs.unbox.ai/docs/uploading-your-first-model-and-dataset) from our documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmp43rYbs9tI"
   },
   "source": [
    "## 1. Loading the dataset\n",
    "\n",
    "First, let's import the libraries we need and load the churn dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hfpWQaUSseVk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have stored the dataset on the following S3 bucket. If, for some reason, you get an error reading the csv directly from it, feel free to copy and paste the URL in your browser and download the csv file. Alternatively, you can also find the dataset on [this Kaggle competition](https://www.kaggle.com/competitions/churn-modelling/overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/tabular-classification/Churn_Modelling.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "I1DxbpEMtH8o",
    "outputId": "24dedc59-1f3b-4a55-f638-f4b3854cef20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading and having a look at the full churn dataset\n",
    "churn_dataset = pd.read_csv(DATASET_URL)\n",
    "\n",
    "churn_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRtUdzF_tYPj"
   },
   "source": [
    "The label we want to learn to predict is in the column `Exited`: retained users have a value of 0 while users that exited have a value of 1. Additionally, we **don't** want to use the `RowNumber`, `CurtomerId`, and `Surname` in our model, so we exclude these columns from our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "F41pDJ-BtZA1"
   },
   "outputs": [],
   "source": [
    "churn_dataset = churn_dataset.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8lXemuatcbd"
   },
   "source": [
    "## 2. Pre-processing the data\n",
    "\n",
    "Notice from one of the previous cell's output that the users' genders and geographies are **categorical features**. Therefore, before feeding the data into the model, we need to encode them. Let's apply a **one-hot-encoding**, which is a common choice when dealing with categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Err2n2xKth6b"
   },
   "outputs": [],
   "source": [
    "# computing some important information about our dataset -- which we'll need in the future \n",
    "categorical_map = {feature: list(churn_dataset[feature].unique()) for feature in [\"Gender\", \"Geography\"]}\n",
    "class_names = [\"Retained\", \"Exited\"]\n",
    "feature_names = churn_dataset.columns.values.tolist()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yuqghEl3tqqM"
   },
   "outputs": [],
   "source": [
    "def data_encode_one_hot(df, encoders):\n",
    "    \"\"\" Encodes categorical features using one-hot encoding. \"\"\"\n",
    "    df = df.copy(True)\n",
    "    df.reset_index(drop=True, inplace=True) # Causes NaNs otherwise\n",
    "    for feature, enc in encoders.items():\n",
    "        print(f\"encoding {feature}\")\n",
    "        enc_df = pd.DataFrame(enc.transform(df[[feature]]).toarray(), columns=enc.get_feature_names([feature]))\n",
    "        df = df.join(enc_df)\n",
    "        df = df.drop(columns=feature)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jqBeeEgPtsft"
   },
   "outputs": [],
   "source": [
    "def create_encoder_dict(df, categorical_feature_names):\n",
    "    \"\"\" Creates encoders for each of the categorical features. \n",
    "        The predict function will need these encoders. \n",
    "    \"\"\"\n",
    "    encoders = {}\n",
    "    for feature in categorical_feature_names:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        enc.fit(df[[feature]])\n",
    "        encoders[feature] = enc\n",
    "    return encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xbVcB6RBtu0k"
   },
   "outputs": [],
   "source": [
    "# creating the encoder dict for the categorical features (gender and geography)\n",
    "encoders = create_encoder_dict(churn_dataset, ['Geography', 'Gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-X5h_OBt62X"
   },
   "source": [
    "## 3. Splitting the data into training and validation sets\n",
    "\n",
    "Now that we are ready to encode our categorical features, let's split the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRo5lsKHtzaB",
    "outputId": "eceb8bd0-331a-4ed8-8e0f-5cdcd272650b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding Geography\n",
      "encoding Gender\n",
      "encoding Geography\n",
      "encoding Gender\n"
     ]
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(churn_dataset.iloc[:, :-1], churn_dataset.iloc[:, -1], test_size=0.2, random_state=42)\n",
    "x_train_one_hot = data_encode_one_hot(x_train, encoders)\n",
    "x_val_one_hot = data_encode_one_hot(x_val, encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TUuXTJQt-7B"
   },
   "source": [
    "## 4. Training and evaluating our model\n",
    "\n",
    "We are going to train a gradient boosting classifier on the training data. Let's then check out what the model's performance is in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2zGCcKLuJu9",
    "outputId": "37896a49-22f3-4857-83a2-756034558ed2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model = GradientBoostingClassifier(random_state=42) \n",
    "sklearn_model.fit(x_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YG389k91uPRl",
    "outputId": "d7dc5335-ee6d-41d3-a426-f140d5a181ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy on the validation set is equal to: 86.4%\n"
     ]
    }
   ],
   "source": [
    "print(\"The model's accuracy on the validation set is equal to: \" + \n",
    "      str(100 * accuracy_score(y_val, sklearn_model.predict(x_val_one_hot))) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrAyZ_TxuSbt"
   },
   "source": [
    "## 5. Unbox part -- have fun creating the next few cells!\n",
    "\n",
    "Now it's up to you! We will just concatenate the x and y, because Unbox expects a single dataframe with features and labels for the upload. \n",
    "\n",
    "Head back to the tutorial to see how you need to fill out the next few cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YaQOONEvuZXk"
   },
   "outputs": [],
   "source": [
    "training_set = pd.concat([x_train, y_train], axis=1)\n",
    "validation_set = pd.concat([x_val, y_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rsKC2qDiu6Dd"
   },
   "outputs": [],
   "source": [
    "# instantiating the client and creating the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TZL_8limu8pe"
   },
   "outputs": [],
   "source": [
    "# defining the predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4szqYCn4vEzf",
    "outputId": "86be4014-2d30-49c2-93c5-d1bf5e8d7e1f"
   },
   "outputs": [],
   "source": [
    "# uploading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iByRoHQNvHBB",
    "outputId": "e197167f-6ffe-40a4-8691-b009dca260f1"
   },
   "outputs": [],
   "source": [
    "# uploading the dataset"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "unbox-tabular-tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
