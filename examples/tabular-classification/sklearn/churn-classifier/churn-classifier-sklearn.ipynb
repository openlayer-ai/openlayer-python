{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef55abc9",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unboxai/examples-gallery/blob/main/tabular-classification/sklearn/churn-classifier/churn-classifier-sklearn.ipynb)\n",
    "\n",
    "\n",
    "# Churn classification using sklearn\n",
    "\n",
    "This notebook illustrates how sklearn models can be upladed to the Unbox platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9d9a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -e \"requirements.txt\" ]; then\n",
    "    curl \"https://raw.githubusercontent.com/unboxai/examples-gallery/main/tabular-classification/sklearn/churn-classifier/requirements.txt\" --output \"requirements.txt\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ce734",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427680f",
   "metadata": {},
   "source": [
    "## Importing the modules and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33179b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc8388",
   "metadata": {},
   "source": [
    "We have stored the dataset on the following S3 bucket. If, for some reason, you get an error reading the csv directly from it, feel free to copy and paste the URL in your browser and download the csv file. Alternatively, you can also find the dataset on [this Kaggle competition](https://www.kaggle.com/competitions/churn-modelling/overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83470097",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/tabular-classification/Churn_Modelling.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40472b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATASET_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 3:-1]\n",
    "y = data.iloc[:, -1]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a37403",
   "metadata": {},
   "source": [
    "## Pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ade4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_encode_one_hot(df, encoders):\n",
    "    \"\"\" Encodes categorical features using one-hot encoding. \"\"\"\n",
    "    df = df.copy(True)\n",
    "    df.reset_index(drop=True, inplace=True) # Causes NaNs otherwise\n",
    "    for feature, enc in encoders.items():\n",
    "        enc_df = pd.DataFrame(enc.transform(df[[feature]]).toarray(), columns=enc.get_feature_names([feature]))\n",
    "        df = df.join(enc_df)\n",
    "        df = df.drop(columns=feature)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a1b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder_dict(df, categorical_feature_names):\n",
    "    \"\"\" Creates encoders for each of the categorical features. \n",
    "        The predict function will need these encoders. \n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    encoders = {}\n",
    "    for feature in categorical_feature_names:\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        enc.fit(df[[feature]])\n",
    "        encoders[feature] = enc\n",
    "    return encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248556af",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = create_encoder_dict(X, ['Geography', 'Gender'])\n",
    "\n",
    "X_enc_one_hot = data_encode_one_hot(X, encoders)\n",
    "X_enc_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac0e55",
   "metadata": {},
   "source": [
    "## Splitting the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "x_train_one_hot = data_encode_one_hot(x_train, encoders)\n",
    "x_val_one_hot = data_encode_one_hot(x_val, encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03e8f4",
   "metadata": {},
   "source": [
    "## Training and evaluating the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee882b61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sklearn_model = LogisticRegression(random_state=1300)\n",
    "sklearn_model.fit(x_train_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f603d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_val, sklearn_model.predict(x_val_one_hot)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c514e1",
   "metadata": {},
   "source": [
    "## Unbox part!\n",
    "\n",
    "### pip installing unboxapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb70c96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install unboxapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5c372",
   "metadata": {},
   "source": [
    "### Instantiating the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a38cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unboxapi\n",
    "\n",
    "client = unboxapi.UnboxClient(\"YOUR_API_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4031585",
   "metadata": {},
   "source": [
    "### Creating a project on the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5562a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unboxapi.tasks import TaskType\n",
    "\n",
    "project = client.create_or_load_project(name=\"Churn Prediction\",\n",
    "                                        task_type=TaskType.TabularClassification,\n",
    "                                        description=\"Evaluation of ML approaches to predict churn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db90bf9",
   "metadata": {},
   "source": [
    "### Uploading the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7355e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some variables that will be used for the dataset upload\n",
    "class_names = [\"Retained\", \"Exited\"]\n",
    "feature_names = list(x_val.columns)\n",
    "\n",
    "# Add the ground truths to the original dataset for Unbox\n",
    "validation_set = x_val.copy()\n",
    "validation_set['churn'] = y_val.values\n",
    "training_set = x_train.copy()\n",
    "training_set['churn'] = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = project.add_dataframe(\n",
    "    df=validation_set,\n",
    "    class_names=class_names,\n",
    "    label_column_name='churn',\n",
    "    commit_message='first commit!',\n",
    "    feature_names=feature_names,\n",
    "    categorical_feature_names=[\"Gender\", \"Geography\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da0afb",
   "metadata": {},
   "source": [
    "### Uploading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe9352",
   "metadata": {},
   "source": [
    "First, it is important to create a `predict_proba` function, which is how Unbox interacts with your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(model, input_features: np.ndarray, col_names, one_hot_encoder, encoders):\n",
    "    \"\"\"Convert the raw input_features into one-hot encoded features\n",
    "    using our one hot encoder and each feature's encoder. \"\"\"\n",
    "    df = pd.DataFrame(input_features, columns=col_names)\n",
    "    encoded_df = one_hot_encoder(df, encoders)\n",
    "    return model.predict_proba(encoded_df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50297977",
   "metadata": {},
   "source": [
    "Let's test the `predict_proba` function to make sure the input-output format is consistent with what Unbox expects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674147b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba(sklearn_model, x_val[:3][feature_names].to_numpy(), feature_names, data_encode_one_hot, encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fe506e",
   "metadata": {},
   "source": [
    "Now, we can upload the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace580e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unboxapi.models import ModelType\n",
    "\n",
    "model = project.add_model(\n",
    "    function=predict_proba, \n",
    "    model=sklearn_model,\n",
    "    model_type=ModelType.sklearn,\n",
    "    class_names=class_names,\n",
    "    name='Churn Classifier',\n",
    "    commit_message='this is my churn classification model',\n",
    "    feature_names=feature_names,\n",
    "    train_sample_df=training_set[:3000],\n",
    "    train_sample_label_column_name='churn',\n",
    "    categorical_feature_names=[\"Gender\", \"Geography\"],\n",
    "    col_names=feature_names,\n",
    "    requirements_txt_file='requirements.txt',\n",
    "    one_hot_encoder=data_encode_one_hot,\n",
    "    encoders=encoders,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294a378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
