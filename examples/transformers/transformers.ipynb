{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "functional-football",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "designing-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "noticed-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sonic-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "handmade-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(model, tokenizer, text):\n",
    "    \n",
    "    encoding = tokenizer.encode_plus(text, return_tensors=\"pt\") \n",
    "    \n",
    "    result = model(**encoding)\n",
    "\n",
    "    list_results = softmax(result[0].detach().numpy()[0]).tolist()\n",
    "  \n",
    "    return list_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "auburn-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba_batch(model, tokenizer, texts):\n",
    "    \n",
    "    encodings = [\n",
    "        tokenizer.encode_plus(\n",
    "            text, return_tensors=\"pt\"\n",
    "        ) for text in texts]\n",
    "    \n",
    "    results = [\n",
    "        model(**encoding) for encoding in encodings\n",
    "    ]\n",
    "    \n",
    "    list_results = [\n",
    "        softmax(result[0].detach().numpy()[0]).tolist()\n",
    "        for result in results\n",
    "    ]\n",
    "        \n",
    "    return list_results, ['negative', 'positive'], [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "civic-click",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0016732359072193503, 0.9983267784118652]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba(model, tokenizer, \"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "certified-philosophy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0.0016732359072193503, 0.9983267784118652],\n",
       "  [0.9684281349182129, 0.031571850180625916]],\n",
       " ['negative', 'positive'],\n",
       " [0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba_batch(model, tokenizer, [\"hi\", \"bye\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-simon",
   "metadata": {},
   "source": [
    "# Unbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-termination",
   "metadata": {},
   "source": [
    "### Pack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "happy-division",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User is not logged in.\n"
     ]
    }
   ],
   "source": [
    "import unboxapi\n",
    "client = unboxapi.UnboxClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "solar-algebra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-12 14:46:04,423] INFO - BentoService bundle 'TransformersModel:20210512144603_12CC1E' saved to: /Users/gbayomi/bentoml/repository/TransformersModel/20210512144603_12CC1E\n"
     ]
    }
   ],
   "source": [
    "saved_path = client.pack_model(\n",
    "    function=predict_proba_batch, \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    model_name=\"TransformersModel\",\n",
    "    model_type=\"transformers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-freight",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "provincial-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "upset-newcastle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-12 14:46:05,643] WARNING - Module `template_model` already loaded, using existing imported module.\n"
     ]
    }
   ],
   "source": [
    "bento_model = bentoml.load(saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-bible",
   "metadata": {},
   "source": [
    "### Test locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "answering-craft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'negative': 0.0001369865203741938, 'positive': 0.9998631477355957}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bento_model.predict([{\"text\": \"great\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "naughty-adapter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'negative': 0.0001369865203741938, 'positive': 0.9998631477355957},\n",
       "  {'negative': 0.9997530579566956, 'positive': 0.0002470429753884673}]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bento_model.predictbatch([{\"batch\": [\"great\", \"terrible\"]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "naughty-notion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1, 0], ['terrible', 'great'])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bento_model.predictactive([{\"batch\": [\"great\", \"terrible\"], \"n_instances\": 2}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-rachel",
   "metadata": {},
   "source": [
    "### Test as an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "knowing-frame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-12 14:46:13,318] INFO - Getting latest version TransformersModel:20210512144603_12CC1E\n",
      "[2021-05-12 14:46:15,977] INFO - {'service_name': 'TransformersModel', 'service_version': '20210512144603_12CC1E', 'api': 'predict', 'task': {'data': '{\"text\": \"Which baking dish is best to bake a banana bread ?\"}', 'task_id': '8a766a46-f614-43be-9995-8cd17f14899f', 'cli_args': ('--input', '{\"text\": \"Which baking dish is best to bake a banana bread ?\"}'), 'inference_job_args': {}}, 'result': {'data': '{\"negative\": 0.9985238313674927, \"positive\": 0.0014760877238586545}', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '8a766a46-f614-43be-9995-8cd17f14899f'}\n",
      "{\"negative\": 0.9985238313674927, \"positive\": 0.0014760877238586545}\n"
     ]
    }
   ],
   "source": [
    "!bentoml run TransformersModel:latest predict --input '{\"text\": \"Which baking dish is best to bake a banana bread ?\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "engaged-world",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-12 14:46:18,030] INFO - Getting latest version TransformersModel:20210512144603_12CC1E\n",
      "[2021-05-12 14:46:20,402] INFO - {'service_name': 'TransformersModel', 'service_version': '20210512144603_12CC1E', 'api': 'predictbatch', 'task': {'data': '{\"batch\": [\"great\", \"terrible\"]}', 'task_id': '5256ca7f-bf98-4526-bcec-a55cfeb33341', 'cli_args': ('--input', '{\"batch\": [\"great\", \"terrible\"]}'), 'inference_job_args': {}}, 'result': {'data': '[{\"negative\": 0.0001369865203741938, \"positive\": 0.9998631477355957}, {\"negative\": 0.9997530579566956, \"positive\": 0.0002470429753884673}]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '5256ca7f-bf98-4526-bcec-a55cfeb33341'}\n",
      "[{\"negative\": 0.0001369865203741938, \"positive\": 0.9998631477355957}, {\"negative\": 0.9997530579566956, \"positive\": 0.0002470429753884673}]\n"
     ]
    }
   ],
   "source": [
    "!bentoml run TransformersModel:latest predictbatch --input '{\"batch\": [\"great\", \"terrible\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fatal-timeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-12 14:46:22,450] INFO - Getting latest version TransformersModel:20210512144603_12CC1E\n",
      "[2021-05-12 14:46:24,895] INFO - {'service_name': 'TransformersModel', 'service_version': '20210512144603_12CC1E', 'api': 'predictactive', 'task': {'data': '{\"batch\": [\"great\", \"terrible\"], \"n_instances\": 2}', 'task_id': 'b938f3c8-f6df-48e7-a13b-5e3ca05f7028', 'cli_args': ('--input', '{\"batch\": [\"great\", \"terrible\"], \"n_instances\": 2}'), 'inference_job_args': {}}, 'result': {'data': '[[1, 0], [\"terrible\", \"great\"]]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': 'b938f3c8-f6df-48e7-a13b-5e3ca05f7028'}\n",
      "[[1, 0], [\"terrible\", \"great\"]]\n"
     ]
    }
   ],
   "source": [
    "!bentoml run TransformersModel:latest predictactive --input '{\"batch\": [\"great\", \"terrible\"], \"n_instances\": 2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-german",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
