{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "e4b6f9ba",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openlayer-ai/examples-gallery/blob/main/text-classification/custom/stacked-models/fasttext-stacked.ipynb)\n",
                "\n",
                "\n",
                "# Text classification using a custom\n",
                "\n",
                "This notebook illustrates how custom models can be upladed to the Openlayer platform. In this particular case, we train two fastText models on different datasets and then combine them to do inference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "f980cec2",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "\n",
                "if [ ! -e \"requirements.txt\" ]; then\n",
                "    curl \"https://raw.githubusercontent.com/openlayer-ai/examples-gallery/main/text-classification/custom/stacked-models/requirements.txt\" --output \"requirements.txt\"\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4fcf8e70",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d51c6a93",
            "metadata": {},
            "source": [
                "## Importing the modules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "bc5fc92e",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import fasttext\n",
                "import numpy as np"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "200513e6",
            "metadata": {},
            "source": [
                "## Training two fastText models on two datasets"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ff4706a7",
            "metadata": {},
            "source": [
                "We have stored the datasets on the following S3 bucket. If, for some reason, you get an error with the `curl`, feel free to copy and paste the URL in your browser and download the txt file. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c1e4747d",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "\n",
                "if [ ! -e \"rec.txt\" ]; then\n",
                "    curl \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/text-classification/rec.txt\" --output \"rec.txt\"\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a54e7139",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "\n",
                "if [ ! -e \"rec_type.txt\" ]; then\n",
                "    curl -0 \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/text-classification/rec_type.txt\" -o \"rec_type.txt\" --output \"rec_type.txt\"\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "03b71c88",
            "metadata": {},
            "outputs": [],
            "source": [
                "rec_model = fasttext.train_supervised(input=\"rec.txt\", lr=0.3, epoch=100, loss='hs')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fa17bdaa",
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "rec_type_model = fasttext.train_supervised(input=\"rec_type.txt\", lr=0.3, epoch=100, loss='hs')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "52cf1d49",
            "metadata": {},
            "source": [
                "Let's inspect how each model predicts the same sentence:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "fc97bdd2",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(([['__label__not.rec']], [array([0.9199592], dtype=float32)]),\n",
                            " ([['__label__rec.autos']], [array([0.635268], dtype=float32)]))"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "rec_model.predict([\"science and politics\"]), rec_type_model.predict([\"science and politics\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b8273820",
            "metadata": {},
            "source": [
                " The predictions are different, mainly because on the dataset `rec.txt`, there are only 2 classes represented, namely `not.rec` and `rec`. On the other hand, on the `rec_type.txt` dataset, there are 4 classes: `rec.sport.hockey`, `rec.motorcycles`, `rec.sport.baseball`, and `rec.autos`. Let's just confirm that:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "0e8e20fa",
            "metadata": {},
            "outputs": [],
            "source": [
                "rec_class_names = [s.replace(\"__label__\", \"\") for s in rec_model.labels]\n",
                "rec_type_class_names = [s.replace(\"__label__\", \"\") for s in rec_type_model.labels]\n",
                "rec_k = len(rec_class_names)\n",
                "rec_type_k = len(rec_type_class_names)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "5accb0ee",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of classes on the `rec.txt` dataset: 2\n",
                        "Number of classes on the `rec_type.txt` dataset: 4\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Number of classes on the `rec.txt` dataset: {rec_k}\")\n",
                "print(f\"Number of classes on the `rec_type.txt` dataset: {rec_type_k}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "ec1ea908",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Classes represented on the `rec.txt` dataset: ['not.rec', 'rec']\n",
                        "Classes represented on the `rec_type.txt` dataset: ['rec.sport.hockey', 'rec.motorcycles', 'rec.sport.baseball', 'rec.autos']\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Classes represented on the `rec.txt` dataset: {rec_class_names}\")\n",
                "print(f\"Classes represented on the `rec_type.txt` dataset: {rec_type_class_names}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "66f63ef7",
            "metadata": {},
            "source": [
                "## Defining how to combine the two model's predictions for inference\n",
                "\n",
                "For inference, we want to use a combination of each model's prediction. Let's define the function `get_predictions`, which, for a given text sample, combines the predictions of both models:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "1dfec9f3",
            "metadata": {},
            "outputs": [],
            "source": [
                "all_class_names = ['not.rec', 'rec.sport.hockey', 'rec.motorcycles', 'rec.sport.baseball', 'rec.autos']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "1984afd9",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_predictions(models, text_list):\n",
                "    \n",
                "    rec_model, rec_type_model = models\n",
                "    \n",
                "    predictions = rec_model.predict(text_list, k=rec_k)\n",
                "    x, y = predictions\n",
                "    \n",
                "    predictions = rec_type_model.predict(text_list, k=rec_k)\n",
                "    x2, y2 = predictions\n",
                "    \n",
                "    probabilities_full_list = []\n",
                "    for rec_label_list, rec_prob_list, rec_type_label_list, rec_type_prob_list in zip(x, y, x2, y2):\n",
                "        rec_label_prob_pair_dict = {}\n",
                "        rec_type_label_prob_pair_dict = {}\n",
                "        \n",
                "        for rec_lbl, rec_prob, rec_type_lbl, rec_type_prob in zip(\n",
                "            rec_label_list, rec_prob_list, rec_type_label_list, rec_type_prob_list\n",
                "        ):\n",
                "            rec_label_prob_pair_dict[\n",
                "                rec_lbl.replace(\"__label__\", \"\")\n",
                "            ] = rec_prob\n",
                "            rec_type_label_prob_pair_dict[\n",
                "                rec_type_lbl.replace(\"__label__\", \"\")\n",
                "            ] = rec_type_prob\n",
                "        \n",
                "        rec_weight = rec_label_prob_pair_dict['rec']\n",
                "        not_rec_weight = rec_label_prob_pair_dict['not.rec']\n",
                "        probabilities_list = []\n",
                "        \n",
                "        if rec_weight > not_rec_weight:\n",
                "            for cls in all_class_names:\n",
                "                if cls in rec_type_label_prob_pair_dict:\n",
                "                    p = rec_type_label_prob_pair_dict[cls]\n",
                "                    probabilities_list.append(p)\n",
                "                else:\n",
                "                    probabilities_list.append(0.0)\n",
                "        \n",
                "        if not_rec_weight > rec_weight:\n",
                "            for cls in all_class_names:\n",
                "                if cls == 'not.rec':\n",
                "                    p = rec_label_prob_pair_dict[cls]\n",
                "                    probabilities_list.append(p)\n",
                "                elif cls in rec_type_label_prob_pair_dict:\n",
                "                    p = rec_type_label_prob_pair_dict[cls]*rec_weight\n",
                "                    probabilities_list.append(p)\n",
                "                else:\n",
                "                    probabilities_list.append(0.0)\n",
                "                    \n",
                "        probabilities_full_list.append(probabilities_list)\n",
                "        \n",
                "        \n",
                "    return np.array(probabilities_full_list)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "04a157a4",
            "metadata": {},
            "source": [
                "Now, let's see how the model predicts a couple sample sentences:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "85fa756a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[0.99093217, 0.        , 0.00269653, 0.        , 0.00241348],\n",
                            "       [0.        , 0.22874895, 0.        , 0.35802186, 0.        ]])"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "phrases = [\"science\", \"motorcycles are cool\"]\n",
                "\n",
                "get_predictions((rec_model, rec_type_model), phrases)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "979b2c5b",
            "metadata": {},
            "source": [
                "## Saving the model binaries \n",
                "\n",
                "Finally, we can save our trained models for packaging."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "b3836047",
            "metadata": {},
            "outputs": [],
            "source": [
                "folder_name = \"./dependencies\"\n",
                "rec_model_path = f\"{folder_name}/rec_model.bin\"\n",
                "rec_type_model_path = f\"{folder_name}/rec_type_model.bin\"\n",
                "\n",
                "# Save model binaries for packaging\n",
                "os.makedirs(folder_name)\n",
                "rec_model.save_model(rec_model_path)\n",
                "rec_type_model.save_model(rec_type_model_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3c47c98e",
            "metadata": {},
            "source": [
                "## Openlayer part!\n",
                "\n",
                "### pip installing openlayer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "223cedb9",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install openlayer"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0ebbba99",
            "metadata": {},
            "source": [
                "### Instantiating the client"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "fb1d8a3d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import openlayer\n",
                "\n",
                "client = openlayer.OpenlayerClient(\"YOUR_API_KEY_HERE\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "29d5ca25",
            "metadata": {},
            "source": [
                "### Creating a project on the platform"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "75a77aa7",
            "metadata": {},
            "outputs": [],
            "source": [
                "from openlayer.tasks import TaskType\n",
                "\n",
                "project = client.create_or_load_project(name=\"FastText Stacked Model\",\n",
                "                                        task_type=TaskType.TextClassification,\n",
                "                                        description=\"Project to Demo Fasttext Stacked\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a5efe157",
            "metadata": {},
            "source": [
                "### Uploading the model"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2d02b0b5",
            "metadata": {},
            "source": [
                "First, we define the `custom_model_code`, which is the code that needs to be executed before running inference with our combined models. In this case, we need to load the model binaries:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "47f2fecf",
            "metadata": {},
            "outputs": [],
            "source": [
                "custom_model_code = f\"\"\"\n",
                "import fasttext\n",
                "\n",
                "rec_model = fasttext.load_model(\"{rec_model_path}\")\n",
                "rec_type_model = fasttext.load_model(\"{rec_type_model_path}\")\n",
                "model = (rec_model, rec_type_model)\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bfb2b4cd",
            "metadata": {},
            "source": [
                "Now, we are ready to upload it to Openlayer as a custom model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5e6c275c",
            "metadata": {},
            "outputs": [],
            "source": [
                "from openlayer.models import ModelType\n",
                "\n",
                "model = project.add_model(\n",
                "    function=get_predictions, \n",
                "    model=None,\n",
                "    dependent_dir=folder_name,\n",
                "    custom_model_code=custom_model_code,\n",
                "    model_type=ModelType.custom,\n",
                "    class_names=all_class_names,\n",
                "    requirements_txt_file=\"requirements.txt\",\n",
                "    name='Stacked model',\n",
                "    commit_message='there are two models here'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ebeb6e6d",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}