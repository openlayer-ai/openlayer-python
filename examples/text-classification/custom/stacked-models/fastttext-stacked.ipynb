{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b6f9ba",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unboxai/examples-gallery/blob/main/text-classification/demo-banking.ipynb)\n",
    "\n",
    "\n",
    "# Text classification using a custom\n",
    "\n",
    "This notebook illustrates how custom models can be upladed to the Unbox platform. In this particular case, we train two fastText models on different datasets and then combine them to do inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51c6a93",
   "metadata": {},
   "source": [
    "## Importing the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5fc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fasttext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200513e6",
   "metadata": {},
   "source": [
    "## Training two fastText models on two datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4706a7",
   "metadata": {},
   "source": [
    "We have stored the datasets on the following S3 bucket. If, for some reason, you get an error with the `curl`, feel free to copy and paste the URL in your browser and download the txt file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e4747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13.3M  100 13.3M    0     0  2034k      0  0:00:06  0:00:06 --:--:-- 2714k\n"
     ]
    }
   ],
   "source": [
    "!curl -0 https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/text-classification/rec.txt -o rec.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a54e7139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1952k  100 1952k    0     0   840k      0  0:00:02  0:00:02 --:--:--  842k\n"
     ]
    }
   ],
   "source": [
    "!curl -0 https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/text-classification/rec_type.txt -o rec_type.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03b71c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 2M words\n",
      "Number of words:  211125\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 6906188 lr:  0.000000 avg.loss:  0.396676 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "rec_model = fasttext.train_supervised(input=\"rec.txt\", lr=0.3, epoch=100, loss='hs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa17bdaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  49236\n",
      "Number of labels: 4\n",
      "Progress: 100.0% words/sec/thread: 6616957 lr:  0.000000 avg.loss:  1.092409 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "rec_type_model = fasttext.train_supervised(input=\"rec_type.txt\", lr=0.3, epoch=100, loss='hs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf1d49",
   "metadata": {},
   "source": [
    "Let's inspect how each model predicts the same sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc97bdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([['__label__not.rec']], [array([0.914432], dtype=float32)]),\n",
       " ([['__label__rec.autos']], [array([0.61953795], dtype=float32)]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_model.predict([\"science and politics\"]), rec_type_model.predict([\"science and politics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8273820",
   "metadata": {},
   "source": [
    " The predictions are different, mainly because on the dataset `rec.txt`, there are only 2 classes represented, namely `not.rec` and `rec`. On the other hand, on the `rec_type.txt` dataset, there are 4 classes: `rec.sport.hockey`, `rec.motorcycles`, `rec.sport.baseball`, and `rec.autos`. Let's just confirm that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e8e20fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_class_names = [s.replace(\"__label__\", \"\") for s in rec_model.labels]\n",
    "rec_type_class_names = [s.replace(\"__label__\", \"\") for s in rec_type_model.labels]\n",
    "rec_k = len(rec_class_names)\n",
    "rec_type_k = len(rec_type_class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5accb0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes on the `rec.txt` dataset: 2\n",
      "Number of classes on the `rec_type.txt` dataset: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of classes on the `rec.txt` dataset: {rec_k}\")\n",
    "print(f\"Number of classes on the `rec_type.txt` dataset: {rec_type_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec1ea908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes represented on the `rec.txt` dataset: ['not.rec', 'rec']\n",
      "Classes represented on the `rec_type.txt` dataset: ['rec.sport.hockey', 'rec.motorcycles', 'rec.sport.baseball', 'rec.autos']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classes represented on the `rec.txt` dataset: {rec_class_names}\")\n",
    "print(f\"Classes represented on the `rec_type.txt` dataset: {rec_type_class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f63ef7",
   "metadata": {},
   "source": [
    "## Defining how to combine the two model's predictions for inference\n",
    "\n",
    "For inference, we want to use a combination of each model's prediction. Let's define the function `get_predictions`, which, for a given text sample, combines the predictions of both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dfec9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class_names = ['not.rec', 'rec.sport.hockey', 'rec.motorcycles', 'rec.sport.baseball', 'rec.autos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1984afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(models, text_list):\n",
    "    \n",
    "    rec_model, rec_type_model = models\n",
    "    \n",
    "    predictions = rec_model.predict(text_list, k=rec_k)\n",
    "    x, y = predictions\n",
    "    \n",
    "    predictions = rec_type_model.predict(text_list, k=rec_k)\n",
    "    x2, y2 = predictions\n",
    "    \n",
    "    probabilities_full_list = []\n",
    "    for rec_label_list, rec_prob_list, rec_type_label_list, rec_type_prob_list in zip(x, y, x2, y2):\n",
    "        rec_label_prob_pair_dict = {}\n",
    "        rec_type_label_prob_pair_dict = {}\n",
    "        \n",
    "        for rec_lbl, rec_prob, rec_type_lbl, rec_type_prob in zip(\n",
    "            rec_label_list, rec_prob_list, rec_type_label_list, rec_type_prob_list\n",
    "        ):\n",
    "            rec_label_prob_pair_dict[\n",
    "                rec_lbl.replace(\"__label__\", \"\")\n",
    "            ] = rec_prob\n",
    "            rec_type_label_prob_pair_dict[\n",
    "                rec_type_lbl.replace(\"__label__\", \"\")\n",
    "            ] = rec_type_prob\n",
    "        \n",
    "        rec_weight = rec_label_prob_pair_dict['rec']\n",
    "        not_rec_weight = rec_label_prob_pair_dict['not.rec']\n",
    "        probabilities_list = []\n",
    "        \n",
    "        if rec_weight > not_rec_weight:\n",
    "            for cls in all_class_names:\n",
    "                if cls in rec_type_label_prob_pair_dict:\n",
    "                    p = rec_type_label_prob_pair_dict[cls]\n",
    "                    probabilities_list.append(p)\n",
    "                else:\n",
    "                    probabilities_list.append(0.0)\n",
    "        \n",
    "        if not_rec_weight > rec_weight:\n",
    "            for cls in all_class_names:\n",
    "                if cls == 'not.rec':\n",
    "                    p = rec_label_prob_pair_dict[cls]\n",
    "                    probabilities_list.append(p)\n",
    "                elif cls in rec_type_label_prob_pair_dict:\n",
    "                    p = rec_type_label_prob_pair_dict[cls]*rec_weight\n",
    "                    probabilities_list.append(p)\n",
    "                else:\n",
    "                    probabilities_list.append(0.0)\n",
    "                    \n",
    "        probabilities_full_list.append(probabilities_list)\n",
    "        \n",
    "        \n",
    "    return np.array(probabilities_full_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a157a4",
   "metadata": {},
   "source": [
    "Now, let's see how the model predicts a couple sample sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85fa756a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98981708, 0.00253816, 0.00280518, 0.        , 0.        ],\n",
       "       [0.        , 0.24129315, 0.        , 0.36813089, 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = [\"science\", \"motorcycles are cool\"]\n",
    "\n",
    "get_predictions((rec_model, rec_type_model), phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b2c5b",
   "metadata": {},
   "source": [
    "## Saving the model binaries \n",
    "\n",
    "Finally, we can save our trained models for packaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3836047",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"./dependencies\"\n",
    "rec_model_path = f\"{folder_name}/rec_model.bin\"\n",
    "rec_type_model_path = f\"{folder_name}/rec_type_model.bin\"\n",
    "\n",
    "# Save model binaries for packaging\n",
    "os.makedirs(folder_name)\n",
    "rec_model.save_model(rec_model_path)\n",
    "rec_type_model.save_model(rec_type_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c47c98e",
   "metadata": {},
   "source": [
    "## Unbox part!\n",
    "\n",
    "### Instantiating the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1d8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unboxapi\n",
    "\n",
    "client = unboxapi.UnboxClient(\"YOUR_API_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d5ca25",
   "metadata": {},
   "source": [
    "### Creating a project on the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75a77aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project on Unbox! Check out https://unbox.ai/projects to have a look!\n"
     ]
    }
   ],
   "source": [
    "project = client.create_project(name=\"FastText Stacked Model\",\n",
    "                                description=\"Project to Demo Fasttext Stacked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5efe157",
   "metadata": {},
   "source": [
    "### Uploading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d02b0b5",
   "metadata": {},
   "source": [
    "First, we define the `custom_model_code`, which is the code that needs to be executed before running inference with our combined models. In this case, we need to load the model binaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47f2fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_code = f\"\"\"\n",
    "import fasttext\n",
    "\n",
    "rec_model = fasttext.load_model(\"{rec_model_path}\")\n",
    "rec_type_model = fasttext.load_model(\"{rec_type_model_path}\")\n",
    "model = (rec_model, rec_type_model)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb2b4cd",
   "metadata": {},
   "source": [
    "Now, we are ready to upload it to Unbox as a custom model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e6c275c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bundling model and artifacts...\n",
      "Uploading model to Unbox! Check out https://unbox.ai/models to have a look!\n"
     ]
    }
   ],
   "source": [
    "from unboxapi.models import ModelType\n",
    "from unboxapi.tasks import TaskType\n",
    "\n",
    "model = project.add_model(\n",
    "    function=get_predictions, \n",
    "    model=None,\n",
    "    dependent_dir=folder_name,\n",
    "    custom_model_code=custom_model_code,\n",
    "    model_type=ModelType.custom,\n",
    "    task_type=TaskType.TextClassification,\n",
    "    class_names=all_class_names,\n",
    "    requirements_txt_file=\"./requirements.txt\",\n",
    "    name='Stacked model',\n",
    "    description='there are two models here'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
