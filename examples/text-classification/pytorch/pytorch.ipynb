{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "64ed980e",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unboxai/examples-gallery/blob/main/text-classification/pytorch/pytorch.ipynb)\n",
                "\n",
                "\n",
                "# Text classification using PyTorch\n",
                "\n",
                "This notebook illustrates how PyTorch models can be upladed to the Openlayer platform."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "c9487301",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "\n",
                "if [ ! -e \"requirements.txt\" ]; then\n",
                "    curl \"https://raw.githubusercontent.com/unboxai/examples-gallery/main/text-classification/pytorch/requirements.txt\" --output \"requirements.txt\"\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0f1d6e2d",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d5af8e1d",
            "metadata": {},
            "source": [
                "## Importing the modules and loading the training set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "fb8d43e9",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import time\n",
                "import torch\n",
                "\n",
                "from collections import Counter\n",
                "from torch import nn\n",
                "from torch.utils.data import DataLoader\n",
                "from torchtext.datasets import AG_NEWS\n",
                "from torchtext.data.utils import get_tokenizer\n",
                "from torch.utils.data.dataset import random_split\n",
                "from torchtext.vocab import vocab"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "2a5d7425",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[(3,\n",
                            "  \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\"),\n",
                            " (3,\n",
                            "  'Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\\\which has a reputation for making well-timed and occasionally\\\\controversial plays in the defense industry, has quietly placed\\\\its bets on another part of the market.'),\n",
                            " (3,\n",
                            "  \"Oil and Economy Cloud Stocks' Outlook (Reuters) Reuters - Soaring crude prices plus worries\\\\about the economy and the outlook for earnings are expected to\\\\hang over the stock market next week during the depth of the\\\\summer doldrums.\"),\n",
                            " (3,\n",
                            "  'Iraq Halts Oil Exports from Main Southern Pipeline (Reuters) Reuters - Authorities have halted oil export\\\\flows from the main pipeline in southern Iraq after\\\\intelligence showed a rebel militia could strike\\\\infrastructure, an oil official said on Saturday.'),\n",
                            " (3,\n",
                            "  'Oil prices soar to all-time record, posing new menace to US economy (AFP) AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before the US presidential elections.')]"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_iter = AG_NEWS(split='train')\n",
                "list(train_iter)[:5]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bf6f8d93",
            "metadata": {},
            "source": [
                "## Building the vocabulary and the model "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "4ba18c72",
            "metadata": {},
            "outputs": [],
            "source": [
                "tokenizer = get_tokenizer('basic_english')\n",
                "\n",
                "counter = Counter()\n",
                "for (label, line) in train_iter:\n",
                "    counter.update(tokenizer(line))\n",
                "\n",
                "vocab = vocab(counter, min_freq=1, specials=[\"<unk>\"])\n",
                "vocab.set_default_index(vocab['<unk>'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "7d03c0fe",
            "metadata": {},
            "outputs": [],
            "source": [
                "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
                "label_pipeline = lambda x: int(x)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "2a43dfd9",
            "metadata": {},
            "outputs": [],
            "source": [
                "def collate_batch(batch):\n",
                "    label_list, text_list, offsets = [], [], [0]\n",
                "    for (_label, _text) in batch:\n",
                "        label_list.append(label_pipeline(_label))\n",
                "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
                "        text_list.append(processed_text)\n",
                "        offsets.append(processed_text.size(0))\n",
                "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
                "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
                "    text_list = torch.cat(text_list)\n",
                "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
                "\n",
                "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "225c9a01",
            "metadata": {},
            "outputs": [],
            "source": [
                "class TextClassificationModel(nn.Module):\n",
                "\n",
                "    def __init__(self, vocab_size, embed_dim, num_class):\n",
                "        super(TextClassificationModel, self).__init__()\n",
                "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
                "        self.fc = nn.Linear(embed_dim, num_class)\n",
                "        self.init_weights()\n",
                "\n",
                "    def init_weights(self):\n",
                "        initrange = 0.5\n",
                "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
                "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
                "        self.fc.bias.data.zero_()\n",
                "\n",
                "    def forward(self, text, offsets):\n",
                "        embedded = self.embedding(text, offsets)\n",
                "        return self.fc(embedded)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "da8b2413",
            "metadata": {},
            "outputs": [],
            "source": [
                "def train(dataloader):\n",
                "    model.train()\n",
                "    total_acc, total_count = 0, 0\n",
                "    log_interval = 500\n",
                "    start_time = time.time()\n",
                "\n",
                "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
                "        optimizer.zero_grad()\n",
                "        predited_label = model(text, offsets)\n",
                "        loss = criterion(predited_label, label)\n",
                "        loss.backward()\n",
                "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
                "        optimizer.step()\n",
                "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
                "        total_count += label.size(0)\n",
                "        if idx % log_interval == 0 and idx > 0:\n",
                "            elapsed = time.time() - start_time\n",
                "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
                "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
                "                                              total_acc/total_count))\n",
                "            total_acc, total_count = 0, 0\n",
                "            start_time = time.time()\n",
                "\n",
                "def evaluate(dataloader):\n",
                "    model.eval()\n",
                "    total_acc, total_count = 0, 0\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
                "            predited_label = model(text, offsets)\n",
                "            loss = criterion(predited_label, label)\n",
                "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
                "            total_count += label.size(0)\n",
                "    return total_acc/total_count"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "53def141",
            "metadata": {},
            "outputs": [],
            "source": [
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "num_class = len(set([label for (label, text) in train_iter]))\n",
                "vocab_size = len(vocab)\n",
                "emsize = 64\n",
                "\n",
                "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e1e50d1e",
            "metadata": {},
            "source": [
                "## Training and evaluating the model's performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "6ff581cd",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "| epoch   1 |   500/ 1782 batches | accuracy    0.684\n",
                        "| epoch   1 |  1000/ 1782 batches | accuracy    0.855\n",
                        "| epoch   1 |  1500/ 1782 batches | accuracy    0.877\n",
                        "-----------------------------------------------------------\n",
                        "| end of epoch   1 | time: 14.62s | valid accuracy    0.884 \n",
                        "-----------------------------------------------------------\n",
                        "| epoch   2 |   500/ 1782 batches | accuracy    0.900\n",
                        "| epoch   2 |  1000/ 1782 batches | accuracy    0.896\n",
                        "| epoch   2 |  1500/ 1782 batches | accuracy    0.904\n",
                        "-----------------------------------------------------------\n",
                        "| end of epoch   2 | time: 14.14s | valid accuracy    0.876 \n",
                        "-----------------------------------------------------------\n"
                    ]
                }
            ],
            "source": [
                "# Hyperparameters\n",
                "EPOCHS = 2 # epoch\n",
                "LR = 5  # learning rate\n",
                "BATCH_SIZE = 64 # batch size for training\n",
                "\n",
                "criterion = torch.nn.CrossEntropyLoss()\n",
                "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
                "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
                "total_accu = None\n",
                "train_iter, test_iter = AG_NEWS()\n",
                "train_dataset = list(train_iter)\n",
                "test_dataset = list(test_iter)\n",
                "# Make labels zero indexed\n",
                "test_dataset = [(a - 1, b) for a, b in test_dataset]\n",
                "train_dataset = [(a - 1, b) for a, b in train_dataset]\n",
                "\n",
                "num_train = int(len(train_dataset) * 0.95)\n",
                "split_train_, split_valid_ = \\\n",
                "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
                "\n",
                "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
                "                              shuffle=True, collate_fn=collate_batch)\n",
                "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
                "                              shuffle=True, collate_fn=collate_batch)\n",
                "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
                "                             shuffle=True, collate_fn=collate_batch)\n",
                "\n",
                "for epoch in range(1, EPOCHS + 1):\n",
                "    epoch_start_time = time.time()\n",
                "    train(train_dataloader)\n",
                "    accu_val = evaluate(valid_dataloader)\n",
                "    if total_accu is not None and total_accu > accu_val:\n",
                "        scheduler.step()\n",
                "    else:\n",
                "        total_accu = accu_val\n",
                "    print('-' * 59)\n",
                "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
                "          'valid accuracy {:8.3f} '.format(epoch,\n",
                "                                           time.time() - epoch_start_time,\n",
                "                                           accu_val))\n",
                "    print('-' * 59)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "3a668a76",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Checking the results of test dataset.\n",
                        "test accuracy    0.876\n"
                    ]
                }
            ],
            "source": [
                "print('Checking the results of test dataset.')\n",
                "accu_test = evaluate(test_dataloader)\n",
                "print('test accuracy {:8.3f}'.format(accu_test))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d3877064",
            "metadata": {},
            "source": [
                "## Openlayer part!\n",
                "\n",
                "### pip installing openlayer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "74137aed",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install openlayer"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ed6f2ed1",
            "metadata": {},
            "source": [
                "### Instantiating the client"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "compressed-occupation",
            "metadata": {},
            "outputs": [],
            "source": [
                "import openlayer\n",
                "\n",
                "client = openlayer.OpenlayerClient(\"YOUR_API_KEY_HERE\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "df481727",
            "metadata": {},
            "source": [
                "### Creating a project on the platform"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19408128",
            "metadata": {},
            "outputs": [],
            "source": [
                "from openlayer.tasks import TaskType\n",
                "\n",
                "project = client.create_or_load_project(name=\"Text classification with PyTorch\",\n",
                "                                        task_type=TaskType.TextClassification,\n",
                "                                        description=\"Evaluating NN for text classification\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e9a2f6d4",
            "metadata": {},
            "source": [
                "### Uploading the validation set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "3e063413",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creating a pandas df with the validation set\n",
                "df = pd.DataFrame(test_dataset, columns=[\"label\", \"text\"])[:1000]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a908a321",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = project.add_dataframe(\n",
                "    df=df,\n",
                "    class_names=['world', 'sports', 'business', 'sci/tec'],\n",
                "    label_column_name='label',\n",
                "    text_column_name='text',\n",
                "    commit_message='this is my Pytorch test dataset'\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fadb4238",
            "metadata": {},
            "source": [
                "### Uploading the model\n",
                "\n",
                "First, it is important to create a `predict_proba` function, which is how Openlayer interacts with your model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "supposed-survey",
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_proba(model, texts, tokenizer_fn, vocab):\n",
                "    with torch.no_grad():\n",
                "        texts = [\n",
                "            torch.tensor(\n",
                "                [vocab[token] for token in tokenizer_fn(text)]\n",
                "            ) \n",
                "            for text in texts]\n",
                "        text_list = torch.tensor(torch.cat(texts)).long()\n",
                "        \n",
                "        offsets = [0]\n",
                "        for text in texts:\n",
                "            offsets.append(text.size(0))\n",
                "        offsets = torch.tensor(offsets[:-1]).cumsum(dim=0).long()\n",
                "        \n",
                "        output = model(text_list, offsets)\n",
                "        \n",
                "        return sm(output).numpy().tolist()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4e4868e1",
            "metadata": {},
            "source": [
                "Let's test the `predict_proba` function to make sure the input-output format is consistent with what Openlayer expects:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "north-valuation",
            "metadata": {},
            "outputs": [],
            "source": [
                "sm = torch.nn.Softmax()\n",
                "ag_news_label = {1: \"World\",\n",
                "                 2: \"Sports\",\n",
                "                 3: \"Business\",\n",
                "                 4: \"Sci/Tec\"}\n",
                "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
                "    enduring the season’s worst weather conditions on Sunday at The \\\n",
                "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
                "    considering the wind and the rain was a respectable showing. \\\n",
                "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
                "    was another story. With temperatures in the mid-80s and hardly any \\\n",
                "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
                "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
                "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
                "    was even more impressive considering he’d never played the \\\n",
                "    front nine at TPC Southwind.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "comprehensive-jenny",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/9z/j3bd32nd47j_l0thnbj6vbnw0000gn/T/ipykernel_22576/710996952.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
                        "  text_list = torch.tensor(torch.cat(texts)).long()\n",
                        "/var/folders/9z/j3bd32nd47j_l0thnbj6vbnw0000gn/T/ipykernel_22576/710996952.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
                        "  return sm(output).numpy().tolist()\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[[0.012467482127249241,\n",
                            "  0.9524526596069336,\n",
                            "  0.0024990958627313375,\n",
                            "  0.03258078917860985],\n",
                            " [0.024693824350833893,\n",
                            "  0.9746410846710205,\n",
                            "  1.4036187167221215e-05,\n",
                            "  0.0006511638639494777]]"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "predict_proba(model, [ex_text_str, \"two\"], tokenizer, vocab)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ea914ad6",
            "metadata": {},
            "source": [
                "Now, we can upload the model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f0b3eb3f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from openlayer.models import ModelType\n",
                "\n",
                "ml_model = project.add_model(\n",
                "    function=predict_proba, \n",
                "    model=model,\n",
                "    model_type=ModelType.pytorch,\n",
                "    class_names=['world', 'sports', 'business', 'sci/tec'],\n",
                "    name='pytorch 4',\n",
                "    commit_message='this is my pytorch model',\n",
                "    requirements_txt_file='requirements.txt',\n",
                "    tokenizer_fn=tokenizer,\n",
                "    vocab=vocab,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "61b00a77",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}