{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant variables\n",
    "MAX_WORDS = 10000\n",
    "REVIEW_CLASSES = ['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXXx5Oc3pOmN"
   },
   "outputs": [],
   "source": [
    "## download dataset from keras.\n",
    "\n",
    "# 10000 high-frequency vocabulary\n",
    "(_X_train, _y_train), (_X_test, _y_test) = keras.datasets.imdb.load_data(num_words=MAX_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8qCnve_-lkO"
   },
   "outputs": [],
   "source": [
    "## check the data\n",
    "print(\"X_train shape: {}\\ny_train shape:{}\".format(_X_train.shape, _y_train.shape))\n",
    "print(type(_X_train.shape))\n",
    "_X_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wJg2FiYpuoX"
   },
   "source": [
    "## Reverse Word Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tr5s_1alpzop"
   },
   "outputs": [],
   "source": [
    "# word_index[<str>] = <int>\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  \n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# word_index.items  <str> to <int>\n",
    "# reverse_word_index <int> to <str>\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '#') for i in text])\n",
    "\n",
    "# <str> to <int>\n",
    "def encode_review(text):\n",
    "    words = text.split(' ')\n",
    "    ids = [word_index[\"<START>\"]]\n",
    "    for w in words:\n",
    "        v = word_index.get(w, word_index[\"<UNK>\"])\n",
    "        # >1000, signed as <UNUSED>\n",
    "        if v > MAX_WORDS:\n",
    "            v = word_index[\"<UNUSED>\"]\n",
    "        ids.append(v)\n",
    "    return ids    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFP_XKVRp4_S"
   },
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jQv-omsHurp"
   },
   "outputs": [],
   "source": [
    "X_train = keras.preprocessing.sequence.pad_sequences(_X_train,\n",
    "                                                     dtype='int32',\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(_X_test,\n",
    "                                                    dtype='int32',\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)\n",
    "\n",
    "\n",
    "# classification. convert y to 2 dims \n",
    "y_train = tf.one_hot(_y_train, depth=2)\n",
    "y_test = tf.one_hot(_y_test, depth=2)\n",
    "\n",
    "\n",
    "print(\"X: \", X_train.shape, X_train.dtype, X_test.dtype)\n",
    "#print(\"y: \", y_train.shape, y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setting\n",
    "model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Embedding(10000, 8),\n",
    "            tf.keras.layers.GlobalAvgPool1D(),\n",
    "            tf.keras.layers.Dense(6, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(2, activation=\"sigmoid\"),\n",
    "        ])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35jv_fzP-llU"
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D6G9oqEV-Se-"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=30, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(model, texts, word_index):\n",
    "    X = [encode_review(t) for t in texts]\n",
    "    X = keras.preprocessing.sequence.pad_sequences(X,\n",
    "                                                   dtype=\"int32\",\n",
    "                                                   value=word_index[\"<PAD>\"],\n",
    "                                                   padding='post',\n",
    "                                                   maxlen=256)\n",
    "    y = model(X)\n",
    "    \n",
    "    return y.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba(model, ['it is funfunnyny.', 'just so good', 'oh, bad'], word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unboxapi\n",
    "client = unboxapi.UnboxClient(\"YOUR_API_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package & Upload to Unbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "\n",
    "for indices in _X_test:\n",
    "    special_chars = [\"<PAD>\", \"<START>\", \"<UNK>\", \"<UNUSED>\"]\n",
    "    text = decode_review(indices)\n",
    "    for char in special_chars:\n",
    "        text = text.replace(char, \"\")\n",
    "    text_data.append(text.strip())\n",
    "    \n",
    "labels = y_test.numpy().argmax(axis=1).tolist()\n",
    "data_dict = {\"text\": text_data, \"labels\": labels}\n",
    "df = pd.DataFrame.from_dict(data_dict).sample(frac=1, random_state=1)[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = client.add_dataframe(\n",
    "    df=df,\n",
    "    class_names=['negative', 'positive'],\n",
    "    label_column_name='labels',\n",
    "    text_column_name='text',\n",
    "    name=\"Tensorflow Validation Data\",\n",
    "    description='this is my sentiment validation dataset'\n",
    ")\n",
    "dataset.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unboxapi.models import ModelType\n",
    "\n",
    "unbox_model = client.add_model(\n",
    "    function=predict_proba, \n",
    "    model=model,\n",
    "    model_type=ModelType.tensorflow,\n",
    "    class_names=['negative', 'positive'],\n",
    "    name='TF Sentiment Model',\n",
    "    description='this is my tensorflow sentiment model',\n",
    "    word_index=word_index\n",
    ")\n",
    "unbox_model.to_dict()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
