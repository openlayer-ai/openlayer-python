{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55acdad9",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unboxai/examples-gallery/blob/main/text-classification/sklearn/sentiment-analysis/sentiment-sklearn.ipynb)\n",
    "\n",
    "\n",
    "# Sentiment analysis using sklearn\n",
    "\n",
    "This notebook illustrates how sklearn models can be upladed to the Unbox platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl \"https://raw.githubusercontent.com/unboxai/examples-gallery/main/text-classification/sklearn/requirements.txt\" --output \"requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813990ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0e018",
   "metadata": {},
   "source": [
    "## Importing the modules and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "atlantic-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f656146",
   "metadata": {},
   "source": [
    "We have stored the dataset on the following S3 bucket. If, for some reason, you get an error reading the csv directly from it, feel free to copy and paste the URL in your browser and download the csv files. Alternatively, you can also find the original datasets on [this Kaggle competition](https://www.kaggle.com/datasets/abhi8923shriv/sentiment-analysis-dataset?select=testdata.manual.2009.06.14.csv). The training set in this example corresponds to the first 20,000 lines of the original training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "080f1d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/text-classification/sentiment-analysis/sentiment_training_set_sample.csv\"\n",
    "VALIDATION_SET_URL = \"https://unbox-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/text-classification/sentiment-analysis/sentiment_validation_set.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incomplete-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['polarity', 'tweetid', 'date', 'query_name', 'user', 'text']\n",
    "df_train = pd.read_csv(TRAINING_SET_URL,\n",
    "                      header=None, \n",
    "                       encoding='ISO-8859-1', index_col=0)\n",
    "\n",
    "df_test = pd.read_csv(VALIDATION_SET_URL,\n",
    "                     header=None,\n",
    "                     encoding='ISO-8859-1')\n",
    "df_train.columns = columns\n",
    "df_test.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e435aecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>date</th>\n",
       "      <th>query_name</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234777</th>\n",
       "      <td>0</td>\n",
       "      <td>1979653827</td>\n",
       "      <td>Sun May 31 03:58:02 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Missscribbler</td>\n",
       "      <td>Just went back from lunch and some small shopp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040566</th>\n",
       "      <td>4</td>\n",
       "      <td>1956965983</td>\n",
       "      <td>Thu May 28 23:09:01 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mike_online</td>\n",
       "      <td>@tbbs: Sarah Connor: So badass, even men from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444362</th>\n",
       "      <td>4</td>\n",
       "      <td>2062251235</td>\n",
       "      <td>Sat Jun 06 22:43:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>JennysMyName</td>\n",
       "      <td>@KayleenDuhh Nope. I don't see it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932855</th>\n",
       "      <td>4</td>\n",
       "      <td>1771210840</td>\n",
       "      <td>Mon May 11 23:33:47 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Scyranth</td>\n",
       "      <td>know ur flippin enemy!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259486</th>\n",
       "      <td>4</td>\n",
       "      <td>1998127816</td>\n",
       "      <td>Mon Jun 01 18:02:16 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>heatherzajac</td>\n",
       "      <td>the ice cream truck came today!!! first &amp;quot;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity     tweetid                          date query_name  \\\n",
       "0                                                                        \n",
       "234777          0  1979653827  Sun May 31 03:58:02 PDT 2009   NO_QUERY   \n",
       "1040566         4  1956965983  Thu May 28 23:09:01 PDT 2009   NO_QUERY   \n",
       "1444362         4  2062251235  Sat Jun 06 22:43:07 PDT 2009   NO_QUERY   \n",
       "932855          4  1771210840  Mon May 11 23:33:47 PDT 2009   NO_QUERY   \n",
       "1259486         4  1998127816  Mon Jun 01 18:02:16 PDT 2009   NO_QUERY   \n",
       "\n",
       "                  user                                               text  \n",
       "0                                                                          \n",
       "234777   Missscribbler  Just went back from lunch and some small shopp...  \n",
       "1040566    mike_online  @tbbs: Sarah Connor: So badass, even men from ...  \n",
       "1444362   JennysMyName                @KayleenDuhh Nope. I don't see it.   \n",
       "932855        Scyranth                            know ur flippin enemy!   \n",
       "1259486   heatherzajac  the ice cream truck came today!!! first &quot;...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b012a4f1",
   "metadata": {},
   "source": [
    "## Training and evaluating the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "multiple-disability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count_vect',\n",
       "                 CountVectorizer(min_df=100, ngram_range=(1, 2),\n",
       "                                 stop_words='english')),\n",
       "                ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model = Pipeline([(\"count_vect\", \n",
    "                           CountVectorizer(min_df=100, \n",
    "                                           ngram_range=(1, 2), \n",
    "                                           stop_words=\"english\"),),\n",
    "                          (\"lr\", LogisticRegression()),])\n",
    "sklearn_model.fit(df_train.text, df_train.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae4d857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.49      0.54       177\n",
      "           2       0.00      0.00      0.00       139\n",
      "           4       0.43      0.83      0.56       182\n",
      "\n",
      "    accuracy                           0.48       498\n",
      "   macro avg       0.34      0.44      0.37       498\n",
      "weighted avg       0.37      0.48      0.40       498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavocid/miniconda3/envs/unbox-examples/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gustavocid/miniconda3/envs/unbox-examples/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/gustavocid/miniconda3/envs/unbox-examples/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = df_test.text, df_test.polarity\n",
    "print(classification_report(y_test, sklearn_model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9193bec1",
   "metadata": {},
   "source": [
    "## Unbox part!\n",
    "\n",
    "### pip installing unboxapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8440a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unboxapi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9049c05",
   "metadata": {},
   "source": [
    "### Instantiating the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "medium-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unboxapi\n",
    "\n",
    "client = unboxapi.UnboxClient(\"YOUR_API_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae672f2",
   "metadata": {},
   "source": [
    "### Creating a project on the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "750132b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created your project. Check out https://unbox.ai/projects!\n"
     ]
    }
   ],
   "source": [
    "from unboxapi import TaskType\n",
    "\n",
    "project = client.create_project(name=\"Sentiment Analysis\",\n",
    "                                task_type=TaskType.TextClassification,\n",
    "                                description=\"Sklearn Sentiment Analysis with Unbox\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb6823",
   "metadata": {},
   "source": [
    "### Uploading the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "digital-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Remove 'neutral' since it isn't in training dataset\n",
    "df_test['polarity'] = df_test['polarity'].replace(2, random.choice([0, 4]))\n",
    "# Make labels monotonically increasing [0,1]\n",
    "df_test['polarity'] = df_test['polarity'].replace(4, 1)\n",
    "df_train['polarity'] = df_train['polarity'].replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "corporate-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading dataset to Unbox! Check out https://unbox.ai/datasets to have a look!\n"
     ]
    }
   ],
   "source": [
    "dataset = project.add_dataframe(\n",
    "    df=df_test,\n",
    "    class_names=['negative', 'positive'],\n",
    "    label_column_name='polarity',\n",
    "    text_column_name='text',\n",
    "    commit_message='this is my sentiment test dataset',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce39ff1e",
   "metadata": {},
   "source": [
    "### Uploading the model\n",
    "\n",
    "First, it is important to create a `predict_proba` function, which is how Unbox interacts with your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "maritime-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(model, text_list):\n",
    "    return model.predict_proba(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876cd559",
   "metadata": {},
   "source": [
    "Let's test the `predict_proba` function to make sure the input-output format is consistent with what Unbox expects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bored-treasury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30904471, 0.69095529],\n",
       "       [0.78541812, 0.21458188]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba(sklearn_model, ['good', 'bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f49c9a",
   "metadata": {},
   "source": [
    "Now, we can upload the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "present-seating",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bundling model and artifacts...\n",
      "Uploading model to Unbox! Check out https://unbox.ai/models to have a look!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavocid/miniconda3/envs/unbox-examples/lib/python3.8/site-packages/joblib/numpy_pickle.py:103: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\n"
     ]
    }
   ],
   "source": [
    "from unboxapi.models import ModelType\n",
    "\n",
    "model = project.add_model(\n",
    "    function=predict_proba, \n",
    "    model=sklearn_model,\n",
    "    model_type=ModelType.sklearn,\n",
    "    class_names=['negative', 'positive'],\n",
    "    name='05.15.2021.sentiment_analyzer',\n",
    "    commit_message='this is my sklearn sentiment model',\n",
    "    requirements_txt_file='requirements.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26956a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
