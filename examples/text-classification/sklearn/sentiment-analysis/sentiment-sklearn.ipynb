{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "55acdad9",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unboxai/examples-gallery/blob/main/text-classification/sklearn/sentiment-analysis/sentiment-sklearn.ipynb)\n",
                "\n",
                "\n",
                "# Sentiment analysis using sklearn\n",
                "\n",
                "This notebook illustrates how sklearn models can be upladed to the Openlayer platform."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "5b1a76a3",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "\n",
                "if [ ! -e \"requirements.txt\" ]; then\n",
                "    curl \"https://raw.githubusercontent.com/unboxai/examples-gallery/main/text-classification/sklearn/sentiment-analysis/requirements.txt\" --output \"requirements.txt\"\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "813990ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a7e0e018",
            "metadata": {},
            "source": [
                "## Importing the modules and loading the dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "atlantic-norway",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.metrics import classification_report\n",
                "from sklearn.pipeline import Pipeline"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8f656146",
            "metadata": {},
            "source": [
                "We have stored the dataset on the following S3 bucket. If, for some reason, you get an error reading the csv directly from it, feel free to copy and paste the URL in your browser and download the csv files. Alternatively, you can also find the original datasets on [this Kaggle competition](https://www.kaggle.com/datasets/abhi8923shriv/sentiment-analysis-dataset?select=testdata.manual.2009.06.14.csv). The training set in this example corresponds to the first 20,000 lines of the original training set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "080f1d41",
            "metadata": {},
            "outputs": [],
            "source": [
                "TRAINING_SET_URL = \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/text-classification/sentiment-analysis/sentiment_training_set_sample.csv\"\n",
                "VALIDATION_SET_URL = \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/text-classification/sentiment-analysis/sentiment_validation_set.csv\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "incomplete-nirvana",
            "metadata": {},
            "outputs": [],
            "source": [
                "columns = ['polarity', 'tweetid', 'date', 'query_name', 'user', 'text']\n",
                "df_train = pd.read_csv(TRAINING_SET_URL,\n",
                "                      header=None, \n",
                "                       encoding='ISO-8859-1', index_col=0)\n",
                "\n",
                "df_test = pd.read_csv(VALIDATION_SET_URL,\n",
                "                     header=None,\n",
                "                     encoding='ISO-8859-1')\n",
                "df_train.columns = columns\n",
                "df_test.columns = columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "e435aecc",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>polarity</th>\n",
                            "      <th>tweetid</th>\n",
                            "      <th>date</th>\n",
                            "      <th>query_name</th>\n",
                            "      <th>user</th>\n",
                            "      <th>text</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>234777</th>\n",
                            "      <td>0</td>\n",
                            "      <td>1979653827</td>\n",
                            "      <td>Sun May 31 03:58:02 PDT 2009</td>\n",
                            "      <td>NO_QUERY</td>\n",
                            "      <td>Missscribbler</td>\n",
                            "      <td>Just went back from lunch and some small shopp...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1040566</th>\n",
                            "      <td>4</td>\n",
                            "      <td>1956965983</td>\n",
                            "      <td>Thu May 28 23:09:01 PDT 2009</td>\n",
                            "      <td>NO_QUERY</td>\n",
                            "      <td>mike_online</td>\n",
                            "      <td>@tbbs: Sarah Connor: So badass, even men from ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1444362</th>\n",
                            "      <td>4</td>\n",
                            "      <td>2062251235</td>\n",
                            "      <td>Sat Jun 06 22:43:07 PDT 2009</td>\n",
                            "      <td>NO_QUERY</td>\n",
                            "      <td>JennysMyName</td>\n",
                            "      <td>@KayleenDuhh Nope. I don't see it.</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>932855</th>\n",
                            "      <td>4</td>\n",
                            "      <td>1771210840</td>\n",
                            "      <td>Mon May 11 23:33:47 PDT 2009</td>\n",
                            "      <td>NO_QUERY</td>\n",
                            "      <td>Scyranth</td>\n",
                            "      <td>know ur flippin enemy!</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1259486</th>\n",
                            "      <td>4</td>\n",
                            "      <td>1998127816</td>\n",
                            "      <td>Mon Jun 01 18:02:16 PDT 2009</td>\n",
                            "      <td>NO_QUERY</td>\n",
                            "      <td>heatherzajac</td>\n",
                            "      <td>the ice cream truck came today!!! first &amp;quot;...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "         polarity     tweetid                          date query_name  \\\n",
                            "0                                                                        \n",
                            "234777          0  1979653827  Sun May 31 03:58:02 PDT 2009   NO_QUERY   \n",
                            "1040566         4  1956965983  Thu May 28 23:09:01 PDT 2009   NO_QUERY   \n",
                            "1444362         4  2062251235  Sat Jun 06 22:43:07 PDT 2009   NO_QUERY   \n",
                            "932855          4  1771210840  Mon May 11 23:33:47 PDT 2009   NO_QUERY   \n",
                            "1259486         4  1998127816  Mon Jun 01 18:02:16 PDT 2009   NO_QUERY   \n",
                            "\n",
                            "                  user                                               text  \n",
                            "0                                                                          \n",
                            "234777   Missscribbler  Just went back from lunch and some small shopp...  \n",
                            "1040566    mike_online  @tbbs: Sarah Connor: So badass, even men from ...  \n",
                            "1444362   JennysMyName                @KayleenDuhh Nope. I don't see it.   \n",
                            "932855        Scyranth                            know ur flippin enemy!   \n",
                            "1259486   heatherzajac  the ice cream truck came today!!! first &quot;...  "
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b012a4f1",
            "metadata": {},
            "source": [
                "## Training and evaluating the model's performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "multiple-disability",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Pipeline(steps=[('count_vect',\n",
                            "                 CountVectorizer(min_df=100, ngram_range=(1, 2),\n",
                            "                                 stop_words='english')),\n",
                            "                ('lr', LogisticRegression())])"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "sklearn_model = Pipeline([(\"count_vect\", \n",
                "                           CountVectorizer(min_df=100, \n",
                "                                           ngram_range=(1, 2), \n",
                "                                           stop_words=\"english\"),),\n",
                "                          (\"lr\", LogisticRegression()),])\n",
                "sklearn_model.fit(df_train.text, df_train.polarity)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ae4d857e",
            "metadata": {},
            "outputs": [],
            "source": [
                "x_test, y_test = df_test.text, df_test.polarity\n",
                "print(classification_report(y_test, sklearn_model.predict(x_test)))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9193bec1",
            "metadata": {},
            "source": [
                "## Openlayer part!\n",
                "\n",
                "### pip installing openlayer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8440a076",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install openlayer"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b9049c05",
            "metadata": {},
            "source": [
                "### Instantiating the client"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "medium-field",
            "metadata": {},
            "outputs": [],
            "source": [
                "import openlayer\n",
                "\n",
                "client = openlayer.OpenlayerClient(\"YOUR_API_KEY_HERE\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4ae672f2",
            "metadata": {},
            "source": [
                "### Creating a project on the platform"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "750132b8",
            "metadata": {},
            "outputs": [],
            "source": [
                "from openlayer import TaskType\n",
                "\n",
                "project = client.create_or_load_project(name=\"Sentiment Analysis\",\n",
                "                                        task_type=TaskType.TextClassification,\n",
                "                                        description=\"Sklearn Sentiment Analysis with Openlayer\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6fdb6823",
            "metadata": {},
            "source": [
                "### Uploading the validation set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "digital-covering",
            "metadata": {},
            "outputs": [],
            "source": [
                "import random\n",
                "\n",
                "# Remove 'neutral' since it isn't in training dataset\n",
                "df_test['polarity'] = df_test['polarity'].replace(2, random.choice([0, 4]))\n",
                "# Make labels monotonically increasing [0,1]\n",
                "df_test['polarity'] = df_test['polarity'].replace(4, 1)\n",
                "df_train['polarity'] = df_train['polarity'].replace(4, 1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "corporate-azerbaijan",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = project.add_dataframe(\n",
                "    df=df_test,\n",
                "    class_names=['negative', 'positive'],\n",
                "    label_column_name='polarity',\n",
                "    text_column_name='text',\n",
                "    commit_message='this is my sentiment test dataset',\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ce39ff1e",
            "metadata": {},
            "source": [
                "### Uploading the model\n",
                "\n",
                "First, it is important to create a `predict_proba` function, which is how Openlayer interacts with your model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "maritime-writing",
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_proba(model, text_list):\n",
                "    return model.predict_proba(text_list)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "876cd559",
            "metadata": {},
            "source": [
                "Let's test the `predict_proba` function to make sure the input-output format is consistent with what Openlayer expects:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "bored-treasury",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[0.30904471, 0.69095529],\n",
                            "       [0.78541812, 0.21458188]])"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "predict_proba(sklearn_model, ['good', 'bad'])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "93f49c9a",
            "metadata": {},
            "source": [
                "Now, we can upload the model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "present-seating",
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "from openlayer.models import ModelType\n",
                "\n",
                "model = project.add_model(\n",
                "    function=predict_proba, \n",
                "    model=sklearn_model,\n",
                "    model_type=ModelType.sklearn,\n",
                "    class_names=['negative', 'positive'],\n",
                "    name='05.15.2021.sentiment_analyzer',\n",
                "    commit_message='this is my sklearn sentiment model',\n",
                "    requirements_txt_file='requirements.txt'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "26956a48",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}