{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "24fdee49",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unboxai/examples-gallery/blob/main/text-classification/transformers/transformers.ipynb)\n",
                "\n",
                "\n",
                "# Text classification using HuggingFace Transformers\n",
                "\n",
                "This notebook illustrates how transformers can be upladed to the Unbox platform."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5984588d",
            "metadata": {},
            "source": [
                "## Importing the modules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "4654b028",
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.special import softmax\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
                "import torch"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "81736602",
            "metadata": {},
            "source": [
                "## Loading the pre-trained model and tokenizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "2941b98d",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "39d5605c03de40e3bfde11b103f21f44",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6a39b98554044a57baf71ab94a3aae06",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "915e9307886f4548a749b10b84219dda",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "tokenizer = AutoTokenizer.from_pretrained(\n",
                "    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "8716646c",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f59303aa89df49069653cf80a19c943e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "model = AutoModelForSequenceClassification.from_pretrained(\n",
                "    \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "98632dac",
            "metadata": {},
            "source": [
                "## Unbox part!\n",
                "\n",
                "### Instantiating the client"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "66d0b86b",
            "metadata": {},
            "outputs": [],
            "source": [
                "import unboxapi\n",
                "\n",
                "client = unboxapi.UnboxClient(\"YOUR_API_KEY_HERE\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0a6cd737",
            "metadata": {},
            "source": [
                "### Creating a project"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "8a69e32c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Creating project on Unbox! Check out https://unbox.ai/projects to have a look!\n"
                    ]
                }
            ],
            "source": [
                "project = client.create_project(name=\"Transformer Demo Project\",\n",
                "                                description=\"Project to Demo Transformers with Unbox\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7dc3ffed",
            "metadata": {},
            "source": [
                "### Uploading the model\n",
                "\n",
                "First, it is important to create a `predict_proba` function, which is how Unbox interacts with your model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "90f0b4f9",
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_proba(model, texts, tokenizer):\n",
                "    \n",
                "    batch = tokenizer(\n",
                "        texts,\n",
                "        padding=True,\n",
                "        truncation=True,\n",
                "        max_length=512,\n",
                "        return_tensors=\"pt\"\n",
                "    )\n",
                "    \n",
                "    with torch.no_grad():        \n",
                "        outputs = model(**batch)\n",
                "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
                "        probs = predictions.detach().numpy().tolist()\n",
                "        \n",
                "        return probs"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c78bfc52",
            "metadata": {},
            "source": [
                "Let's test the `predict_proba` function to make sure the input-output format is consistent with what Unbox expects:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "010bff85",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[[0.00017212914826814085, 0.9998278617858887],\n",
                            " [0.999519944190979, 0.0004800486785825342]]"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "predict_proba(model, [\"good morning!\", \"I've had a horrible day.\"], tokenizer)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5ad9c9bb",
            "metadata": {},
            "source": [
                "Now, we can upload the model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "94f1d89e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Bundling model and artifacts...\n",
                        "Uploading model to Unbox! Check out https://unbox.ai/models to have a look!\n"
                    ]
                }
            ],
            "source": [
                "# Comment this out and uncomment the next section to load the project\n",
                "project = client.create_project(\n",
                "    name=\"Transformer Demo Project\",\n",
                "    description=\"Project to Demo Transformers with Unbox\",\n",
                "    task_type=TaskType.TextClassification,\n",
                ")\n",
                "\n",
                "# Use this for loading the project on subsequent runs\n",
                "'''\n",
                "project = client.load_project(\n",
                "    name=\"Transformer Demo Project\"\n",
                ")\n",
                "'''\n",
                "from unboxapi.tasks import TaskType\n",
                "from unboxapi.models import ModelType\n",
                "\n",
                "model = project.add_model(\n",
                "    function=predict_proba, \n",
                "    model=model,\n",
                "    model_type=ModelType.transformers,\n",
                "    class_names=['negative', 'positive'],\n",
                "    name='transformers.sentiment_analyzer',\n",
                "    description='this is my transformers sentiment model',\n",
                "    tokenizer=tokenizer,\n",
                "    requirements_txt_file='./requirements.txt'\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}