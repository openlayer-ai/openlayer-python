{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98b72b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa.nlu.model import Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3558edb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-10 23:24:30.508447: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-10 23:24:30.525794: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a4057b360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-07-10 23:24:30.525807: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/unbox/opt/miniconda3/envs/api-local/lib/python3.7/site-packages/rasa/utils/tensorflow/layers.py:639: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
     ]
    }
   ],
   "source": [
    "model = Interpreter.load(\"nlu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a22198f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nlu'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_metadata.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac3818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = [\"greet\", \"goodbye\", \"bot_challenge\", \"password_reset\", \"inform\", \n",
    "\"thank\", \"help\", \"problem_email\", \"open_incident\", \"incident_status\", \n",
    "\"out_of_scope\", \"restart\", \"affirm\", \"deny\", \"trigger_handoff\", \n",
    "\"human_handoff\", \"handoff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509e5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(model, text_list):\n",
    "    results = []\n",
    "    \n",
    "    labels = [\"greet\", \"goodbye\", \"bot_challenge\", \"password_reset\", \"inform\", \n",
    "               \"thank\", \"help\", \"problem_email\", \"open_incident\", \"incident_status\", \n",
    "               \"out_of_scope\", \"restart\", \"affirm\", \"deny\", \"trigger_handoff\", \n",
    "               \"human_handoff\", \"handoff\"]\n",
    "    \n",
    "    for text in text_list:\n",
    "        probs = []\n",
    "        output = model.parse(text, only_output_properties=False)\n",
    "        confs = {d['name']:d['confidence'] for d in output['intent_ranking'] if \"id\" in d}\n",
    "        for label in labels:\n",
    "            prob = 0.0\n",
    "            if label in confs:\n",
    "                prob = confs[label]\n",
    "            probs.append(prob)\n",
    "        results.append(probs)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e61e1e",
   "metadata": {},
   "source": [
    "# Unbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ee379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unboxapi\n",
    "client = unboxapi.UnboxClient(\"YOUR_API_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae2a5e0",
   "metadata": {},
   "source": [
    "### upload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee28e943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/unbox/Desktop/unboxapi-python-client/examples/local/temp6\n",
      "/Users/unbox/Desktop/unboxapi-python-client/examples/local/temp6/TemplateModel/nlu\n"
     ]
    }
   ],
   "source": [
    "from unboxapi.models import ModelType\n",
    "\n",
    "model_path = client.add_model(\n",
    "    function=predict_proba, \n",
    "    model=model,\n",
    "    model_type=ModelType.rasa,\n",
    "    class_names=intents,\n",
    "    name='rasa model',\n",
    "    description='this is my rasa model'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4d5305",
   "metadata": {},
   "source": [
    "# Test Bento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ceded69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da35f140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-07-10 23:27:22,601] WARNING - Module `template_model` already loaded, using existing imported module.\n"
     ]
    }
   ],
   "source": [
    "bento_model = bentoml.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb2018b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['hello']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.9999524354934692,\n",
       "  0.0,\n",
       "  9.283241979574086e-07,\n",
       "  1.721418101396921e-07,\n",
       "  3.308567784188199e-07,\n",
       "  1.750023784552468e-06,\n",
       "  1.4346930583997164e-05,\n",
       "  3.443972673267126e-06,\n",
       "  1.5785906271048589e-06,\n",
       "  0.0,\n",
       "  2.3841097984700355e-08,\n",
       "  0.0,\n",
       "  2.5017172447405756e-05,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bento_model.predict({\"text\": [\"hello\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f5084",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml run TemplateModel:latest predict --input '{\"text\": [\"how are you\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f82b737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-07-10 23:28:55,443] INFO - Getting latest version TemplateModel:20210710231743_D4383B\n",
      "[2021-07-10 23:28:55,452] INFO - Starting BentoML API proxy in development mode..\n",
      "[2021-07-10 23:28:55,455] INFO - Starting BentoML API server in development mode..\n",
      "[2021-07-10 23:28:55,623] INFO - Your system nofile limit is 4096, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n",
      "======== Running on http://0.0.0.0:5000 ========\n",
      "(Press CTRL+C to quit)\n",
      "2021-07-10 23:29:01.910419: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-10 23:29:01.938127: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa2e8f3ac40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-07-10 23:29:01.938609: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /Users/unbox/opt/miniconda3/envs/api-local/lib/python3.7/site-packages/rasa/utils/tensorflow/layers.py:639: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
      " * Serving Flask app 'TemplateModel' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n",
      " * Running on http://127.0.0.1:58215/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [10/Jul/2021 23:29:44] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [10/Jul/2021 23:29:44] \"\u001b[36mGET /static_content/swagger-ui.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [10/Jul/2021 23:29:44] \"\u001b[36mGET /static_content/main.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [10/Jul/2021 23:29:44] \"\u001b[36mGET /static_content/readme.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [10/Jul/2021 23:29:44] \"\u001b[36mGET /static_content/swagger-ui-bundle.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [10/Jul/2021 23:29:44] \"\u001b[36mGET /static_content/marked.min.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [10/Jul/2021 23:29:44] \"GET /docs.json HTTP/1.1\" 200 -\n",
      "{'text': ['hello']}\n",
      "[2021-07-10 23:30:04,466] INFO - {'service_name': 'TemplateModel', 'service_version': '20210710232449_D8E7EC', 'api': 'predict', 'task': {'data': '{\"text\":[\"hello\"]}', 'task_id': '0a0ce041-9f59-4958-a5c9-fd2f3885ec74', 'http_headers': (('Host', '0.0.0.0:5000'), ('Connection', 'keep-alive'), ('Content-Length', '18'), ('Accept', '*/*'), ('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36'), ('Content-Type', 'application/json'), ('Origin', 'http://0.0.0.0:5000'), ('Referer', 'http://0.0.0.0:5000/'), ('Accept-Encoding', 'gzip, deflate'), ('Accept-Language', 'en-US,en;q=0.9'))}, 'result': {'data': '[[0.9999524354934692, 0.0, 9.283241979574086e-07, 1.721418101396921e-07, 3.308567784188199e-07, 1.750023784552468e-06, 1.4346930583997164e-05, 3.443972673267126e-06, 1.5785906271048589e-06, 0.0, 2.3841097984700355e-08, 0.0, 2.5017172447405756e-05, 0.0, 0.0, 0.0, 0.0]]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '0a0ce041-9f59-4958-a5c9-fd2f3885ec74'}\n",
      "127.0.0.1 - - [10/Jul/2021 23:30:04] \"POST /predict HTTP/1.1\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve TemplateModel:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd3c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
