{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "noticed-furniture",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exempt-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import time\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offensive-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = AG_NEWS(split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "departmental-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = AG_NEWS(split='train')\n",
    "counter = Counter()\n",
    "for (label, line) in train_iter:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = Vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "french-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: int(x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "handy-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "train_iter = AG_NEWS(split='train')\n",
    "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "widespread-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "academic-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = AG_NEWS(split='train')\n",
    "num_class = len(set([label for (label, text) in train_iter]))\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "indoor-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predited_label = model(text, offsets)\n",
    "        loss = criterion(predited_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predited_label = model(text, offsets)\n",
    "            loss = criterion(predited_label, label)\n",
    "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "essential-meditation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   500/ 1782 batches | accuracy    0.693\n",
      "| epoch   1 |  1000/ 1782 batches | accuracy    0.853\n",
      "| epoch   1 |  1500/ 1782 batches | accuracy    0.876\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 10.60s | valid accuracy    0.884 \n",
      "-----------------------------------------------------------\n",
      "| epoch   2 |   500/ 1782 batches | accuracy    0.898\n",
      "| epoch   2 |  1000/ 1782 batches | accuracy    0.899\n",
      "| epoch   2 |  1500/ 1782 batches | accuracy    0.904\n",
      "-----------------------------------------------------------\n",
      "| end of epoch   2 | time: 10.53s | valid accuracy    0.898 \n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "# Hyperparameters\n",
    "EPOCHS = 2 # epoch\n",
    "LR = 5  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_iter, test_iter = AG_NEWS()\n",
    "train_dataset = list(train_iter)\n",
    "test_dataset = list(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "split_train_, split_valid_ = \\\n",
    "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
    "                              shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(valid_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "        scheduler.step()\n",
    "    else:\n",
    "        total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extensive-template",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    0.891\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader)\n",
    "print('test accuracy {:8.3f}'.format(accu_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-nightmare",
   "metadata": {},
   "source": [
    "# PREDICT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "north-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = torch.nn.Softmax()\n",
    "ag_news_label = {1: \"World\",\n",
    "                 2: \"Sports\",\n",
    "                 3: \"Business\",\n",
    "                 4: \"Sci/Tec\"}\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "supposed-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(model, tokenizer, vocab, texts):\n",
    "    with torch.no_grad():\n",
    "        texts = [\n",
    "            [vocab[token] for token in tokenizer(text)] \n",
    "            for text in texts]\n",
    "        \n",
    "        texts = torch.stack(\n",
    "            [torch.tensor(text) for text in texts]\n",
    "        )\n",
    "        \n",
    "        output = model(texts, None)\n",
    "        return (\n",
    "            sm(output).numpy().tolist(), \n",
    "            list(ag_news_label.values()),\n",
    "            [0, 1, 2, 3]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "comprehensive-jenny",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-07aa0e499264>:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sm(output).numpy().tolist(),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[0.09169654548168182,\n",
       "   0.8639219403266907,\n",
       "   0.0048335157334804535,\n",
       "   0.03954795002937317],\n",
       "  [0.0916965901851654,\n",
       "   0.8639219403266907,\n",
       "   0.0048335157334804535,\n",
       "   0.03954796493053436]],\n",
       " ['World', 'Sports', 'Business', 'Sci/Tec'],\n",
       " [0, 1, 2, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_fn(model, tokenizer, vocab, [ex_text_str, ex_text_str])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-london",
   "metadata": {},
   "source": [
    "# Unbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-north",
   "metadata": {},
   "source": [
    "### Pack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "unable-contemporary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User is not logged in.\n"
     ]
    }
   ],
   "source": [
    "import unboxapi\n",
    "client = unboxapi.UnboxClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "material-settlement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-12 13:25:40,419] WARNING - BentoML by default does not include spacy and torchvision package when using PytorchModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2021-05-12 13:25:41,976] INFO - BentoService bundle 'TorchModel:20210512132540_E7CBFD' saved to: /Users/gbayomi/bentoml/repository/TorchModel/20210512132540_E7CBFD\n"
     ]
    }
   ],
   "source": [
    "saved_path = client.pack_model(\n",
    "    function=predict_fn, \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    vocab=vocab,\n",
    "    model_name=\"TorchModel\",\n",
    "    model_type=\"pytorch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-bacteria",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "experimental-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "banner-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-12 13:25:59,636] WARNING - Module `template_model` already loaded, using existing imported module.\n",
      "[2021-05-12 13:25:59,690] WARNING - BentoML by default does not include spacy and torchvision package when using PytorchModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "[2021-05-12 13:25:59,691] WARNING - pip package requirement torch already exist\n"
     ]
    }
   ],
   "source": [
    "bento_model = bentoml.load(saved_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-invention",
   "metadata": {},
   "source": [
    "### Test locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "oriented-holmes",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-07aa0e499264>:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sm(output).numpy().tolist(),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'World': 3.307048075384955e-07,\n",
       "  'Sports': 7.693777661188506e-06,\n",
       "  'Business': 2.2019364678271813e-06,\n",
       "  'Sci/Tec': 0.9999897480010986}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bento_model.predict([{\"text\": \"great\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "enormous-seating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'World': 3.307048075384955e-07,\n",
       "   'Sports': 7.693770385230891e-06,\n",
       "   'Business': 2.2019364678271813e-06,\n",
       "   'Sci/Tec': 0.9999897480010986},\n",
       "  {'World': 0.0010780768934637308,\n",
       "   'Sports': 0.14372384548187256,\n",
       "   'Business': 0.1999814510345459,\n",
       "   'Sci/Tec': 0.655216634273529}]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bento_model.predictbatch([{\"batch\": [\"great\", \"terrible\"]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sunset-provision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1, 0], ['terrible', 'great'])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bento_model.predictactive([{\"batch\": [\"great\", \"terrible\"], \"n_instances\": 2}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-might",
   "metadata": {},
   "source": [
    "### Test as an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "yellow-freight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-12 13:26:12,327] INFO - Getting latest version TorchModel:20210512132540_E7CBFD\n",
      "[2021-05-12 13:26:13,693] WARNING - BentoML by default does not include spacy and torchvision package when using PytorchModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "<ipython-input-16-07aa0e499264>:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "[2021-05-12 13:26:14,338] INFO - {'service_name': 'TorchModel', 'service_version': '20210512132540_E7CBFD', 'api': 'predict', 'task': {'data': '{\"text\": \"Which baking dish is best to bake a banana bread ?\"}', 'task_id': 'b4a9ff9c-cd1f-4ded-b446-d7979e51910f', 'cli_args': ('--input', '{\"text\": \"Which baking dish is best to bake a banana bread ?\"}'), 'inference_job_args': {}}, 'result': {'data': '{\"World\": 0.03370516747236252, \"Sports\": 0.0010395821882411838, \"Business\": 0.9399195313453674, \"Sci/Tec\": 0.025335798040032387}', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': 'b4a9ff9c-cd1f-4ded-b446-d7979e51910f'}\n",
      "{\"World\": 0.03370516747236252, \"Sports\": 0.0010395821882411838, \"Business\": 0.9399195313453674, \"Sci/Tec\": 0.025335798040032387}\n"
     ]
    }
   ],
   "source": [
    "!bentoml run TorchModel:latest predict --input '{\"text\": \"Which baking dish is best to bake a banana bread ?\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "endless-physics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-12 13:26:18,773] INFO - Getting latest version TorchModel:20210512132540_E7CBFD\n",
      "[2021-05-12 13:26:20,039] WARNING - BentoML by default does not include spacy and torchvision package when using PytorchModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "<ipython-input-16-07aa0e499264>:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "[2021-05-12 13:26:20,553] INFO - {'service_name': 'TorchModel', 'service_version': '20210512132540_E7CBFD', 'api': 'predictbatch', 'task': {'data': '{\"batch\": [\"great\", \"terrible\"]}', 'task_id': 'ac5b0c82-d87d-4409-bb5b-c49928dc06e0', 'cli_args': ('--input', '{\"batch\": [\"great\", \"terrible\"]}'), 'inference_job_args': {}}, 'result': {'data': '[{\"World\": 3.307048075384955e-07, \"Sports\": 7.693770385230891e-06, \"Business\": 2.2019364678271813e-06, \"Sci/Tec\": 0.9999897480010986}, {\"World\": 0.0010780768934637308, \"Sports\": 0.14372384548187256, \"Business\": 0.1999814510345459, \"Sci/Tec\": 0.655216634273529}]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': 'ac5b0c82-d87d-4409-bb5b-c49928dc06e0'}\n",
      "[{\"World\": 3.307048075384955e-07, \"Sports\": 7.693770385230891e-06, \"Business\": 2.2019364678271813e-06, \"Sci/Tec\": 0.9999897480010986}, {\"World\": 0.0010780768934637308, \"Sports\": 0.14372384548187256, \"Business\": 0.1999814510345459, \"Sci/Tec\": 0.655216634273529}]\n"
     ]
    }
   ],
   "source": [
    "!bentoml run TorchModel:latest predictbatch --input '{\"batch\": [\"great\", \"terrible\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "infectious-medication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-12 13:26:23,629] INFO - Getting latest version TorchModel:20210512132540_E7CBFD\n",
      "[2021-05-12 13:26:24,873] WARNING - BentoML by default does not include spacy and torchvision package when using PytorchModelArtifact. To make sure BentoML bundle those packages if they are required for your model, either import those packages in BentoService definition file or manually add them via `@env(pip_packages=['torchvision'])` when defining a BentoService\n",
      "<ipython-input-16-07aa0e499264>:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "[2021-05-12 13:26:25,387] INFO - {'service_name': 'TorchModel', 'service_version': '20210512132540_E7CBFD', 'api': 'predictactive', 'task': {'data': '{\"batch\": [\"great\", \"terrible\"], \"n_instances\": 2}', 'task_id': '44cb616a-a63a-45e7-ae21-3f02553711ca', 'cli_args': ('--input', '{\"batch\": [\"great\", \"terrible\"], \"n_instances\": 2}'), 'inference_job_args': {}}, 'result': {'data': '[[1, 0], [\"terrible\", \"great\"]]', 'http_status': 200, 'http_headers': (('Content-Type', 'application/json'),)}, 'request_id': '44cb616a-a63a-45e7-ae21-3f02553711ca'}\n",
      "[[1, 0], [\"terrible\", \"great\"]]\n"
     ]
    }
   ],
   "source": [
    "!bentoml run TorchModel:latest predictactive --input '{\"batch\": [\"great\", \"terrible\"], \"n_instances\": 2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-appraisal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
