{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "ef55abc9",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openlayer-ai/examples-gallery/blob/main/monitoring/llms/monitoring-llms.ipynb)\n",
                "\n",
                "\n",
                "# <a id=\"top\">Monitoring LLMs</a>\n",
                "\n",
                "This notebook illustrates a typical monitoring flow for LLMs using Openlayer. For more details, refer to the [How to set up monitoring guide](https://docs.openlayer.com/docs/how-to-guides/set-up-monitoring) from the documentation.\n",
                "\n",
                "\n",
                "## <a id=\"toc\">Table of contents</a>\n",
                "\n",
                "1. [**Creating a project and an inference pipeline**](#inference-pipeline) \n",
                "\n",
                "2. [**Publishing production data**](#publish-batches)\n",
                "\n",
                "3. [(Optional) **Uploading a reference dataset**](#reference-dataset)\n",
                "\n",
                "4. [(Optional) **Publishing ground truths**](#ground-truths)\n",
                "\n",
                "Before we start, let's download the sample data and import pandas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3d193436",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "\n",
                "if [ ! -e \"fine_tuning_dataset.csv\" ]; then\n",
                "    curl \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/monitoring/llms/fine_tuning_dataset.csv\" --output \"fine_tuning_dataset.csv\"\n",
                "fi\n",
                "\n",
                "if [ ! -e \"prod_data_no_ground_truths.csv\" ]; then\n",
                "    curl \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/monitoring/llms/prod_data_no_ground_truths.csv\" --output \"prod_data_no_ground_truths.csv\"\n",
                "fi\n",
                "\n",
                "if [ ! -e \"prod_ground_truths.csv\" ]; then\n",
                "    curl \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/monitoring/llms/prod_ground_truths.csv\" --output \"prod_ground_truths.csv\"\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9dce8f60",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c4ea849d",
            "metadata": {},
            "source": [
                "## <a id=\"inference-pipeline\"> 1. Creating a project and an inference pipeline </a>\n",
                "\n",
                "[Back to top](#top)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "05f27b6c",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install openlayer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8504e063",
            "metadata": {},
            "outputs": [],
            "source": [
                "import openlayer\n",
                "\n",
                "client = openlayer.OpenlayerClient(\"YOUR_API_KEY_HERE\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5377494b",
            "metadata": {},
            "outputs": [],
            "source": [
                "from openlayer.tasks import TaskType\n",
                "\n",
                "project = client.create_project(\n",
                "    name=\"Python QA\",\n",
                "    task_type=TaskType.LLM,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ed0c9bf6",
            "metadata": {},
            "source": [
                "Now that you are authenticated and have a project on the platform, it's time to create an inference pipeline. Creating an inference pipeline is what enables the monitoring capabilities in a project."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "147b5294",
            "metadata": {},
            "outputs": [],
            "source": [
                "inference_pipeline = project.create_inference_pipeline()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3c8608ea",
            "metadata": {},
            "source": [
                "## <a id=\"publish-batches\"> 2. Publishing production data </a>\n",
                "\n",
                "[Back to top](#top)\n",
                "\n",
                "In production, as the model makes predictions, the data can be published to Openlayer. This is done with the `publish_batch_data` method. \n",
                "\n",
                "The data published to Openlayer can have a column with **inference ids** and another with **timestamps** (UNIX sec format). These are both optional and, if not provided, will receive default values. The inference id is particularly important if you wish to publish ground truths at a later time. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "918da1f7",
            "metadata": {},
            "outputs": [],
            "source": [
                "production_data = pd.read_csv(\"prod_data_no_ground_truths.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "deec9e95",
            "metadata": {},
            "outputs": [],
            "source": [
                "batch_1 = production_data.loc[:9]\n",
                "batch_2 = production_data.loc[9:18]\n",
                "batch_3 = production_data.loc[18:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "25b66229",
            "metadata": {},
            "outputs": [],
            "source": [
                "batch_1.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1bcf399a",
            "metadata": {},
            "source": [
                "### <a id=\"publish-batches\"> Publish to Openlayer </a>\n",
                "\n",
                "Here, we're simulating three calls to `publish_batch_data`. In practice, this is a code snippet that lives in your inference pipeline and that gets called after the model predictions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1b8f28f8",
            "metadata": {},
            "outputs": [],
            "source": [
                "batch_config = {\n",
                "    \"inputVariableNames\": [\"question\"],\n",
                "    \"outputColumnName\": \"answer\",\n",
                "    \"inferenceIdColumnName\": \"inference_id\",\n",
                "}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bde01a2b",
            "metadata": {},
            "outputs": [],
            "source": [
                "inference_pipeline.publish_batch_data(\n",
                "    batch_df=batch_1,\n",
                "    batch_config=batch_config\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bfc3dea6",
            "metadata": {},
            "outputs": [],
            "source": [
                "inference_pipeline.publish_batch_data(\n",
                "    batch_df=batch_2,\n",
                "    batch_config=batch_config\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "159b4e24",
            "metadata": {},
            "outputs": [],
            "source": [
                "inference_pipeline.publish_batch_data(\n",
                "    batch_df=batch_3,\n",
                "    batch_config=batch_config\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d00f6e8e",
            "metadata": {},
            "source": [
                "**That's it!** You're now able to set up tests and alerts for your production data. The next sections are optional and enable some features on the platform."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "39592b32",
            "metadata": {},
            "source": [
                "## <a id=\"reference-dataset\"> 3. Uploading a reference dataset </a>\n",
                "\n",
                "[Back to top](#top)\n",
                "\n",
                "A reference dataset is optional, but it enables drift monitoring. Ideally, the reference dataset is a representative sample of the training/fine-tuning set used to train the deployed model. In this section, we first load the dataset and then we upload it to Openlayer using the `upload_reference_dataframe` method."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "31809ca9",
            "metadata": {},
            "outputs": [],
            "source": [
                "fine_tuning_data = pd.read_csv(\"./fine_tuning_dataset.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a6336802",
            "metadata": {},
            "source": [
                "### <a id=\"upload-reference\"> Uploading the dataset to Openlayer </a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0f8e23e3",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset_config = {\n",
                "    \"inputVariableNames\": [\"question\"],\n",
                "    \"groundTruthColumnName\": \"ground_truth\",\n",
                "    \"label\": \"reference\"\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f6cf719f",
            "metadata": {},
            "outputs": [],
            "source": [
                "inference_pipeline.upload_reference_dataframe(\n",
                "    dataset_df=fine_tuning_data,\n",
                "    dataset_config=dataset_config\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fbc1fca3",
            "metadata": {},
            "source": [
                "## <a id=\"ground-truths\"> 4. Publishing ground truths for past batches </a>\n",
                "\n",
                "[Back to top](#top)\n",
                "\n",
                "The ground truths are needed to create Performance tests. The `publish_ground_truths` method can be used to update the ground truths for batches of data already published to the Openlayer platform. The inference id is what gets used to merge the ground truths with the corresponding rows."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "03355dcf",
            "metadata": {},
            "outputs": [],
            "source": [
                "ground_truths = pd.read_csv(\"prod_ground_truths.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "903480c8",
            "metadata": {},
            "source": [
                "### <a id=\"publish-truth\">Publish ground truths </a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ccd906c2",
            "metadata": {},
            "outputs": [],
            "source": [
                "inference_pipeline.publish_ground_truths(\n",
                "    df=ground_truths,\n",
                "    ground_truth_column_name=\"ground_truth\",\n",
                "    inference_id_column_name=\"inference_id\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f3749495",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}