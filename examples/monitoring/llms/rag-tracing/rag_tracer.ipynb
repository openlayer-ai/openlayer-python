{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c16ef6-98e7-48d0-b82f-4029a730ff00",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openlayer-ai/examples-gallery/blob/main/monitoring/llms/rag-tracing/rag_tracer.ipynb)\n",
    "\n",
    "\n",
    "# <a id=\"top\">Tracing a RAG system</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21137554-ad8e-444b-bf2e-49393f072956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# OpenAI env variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_KEY_HERE\"\n",
    "\n",
    "# Openlayer env variables\n",
    "os.environ[\"OPENLAYER_API_KEY\"] = \"YOUR_OPENLAYER_API_KEY_HERE\"\n",
    "os.environ[\"OPENLAYER_PROJECT_NAME\"] = \"YOUR_OPENLAYER_PROJECT_NAME_HERE\" # Where the traces will be uploaded to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b25a1f-529e-45c5-90e5-26485914f511",
   "metadata": {},
   "source": [
    "## Defining and decorating our RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f8d80-d49a-48f0-8c12-350045dff985",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -e \"context.txt\" ]; then\n",
    "    curl \"https://raw.githubusercontent.com/openlayer-ai/examples-gallery/main/monitoring/llms/rag-tracing/context.txt\" --output \"context.txt\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d470d7-3aa0-4703-a9e7-cab24325a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from openlayer import llm_monitors\n",
    "from openlayer.tracing import tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8070d3f-ebec-4faf-8959-23e6ac22737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RagPipeline:\n",
    "    def __init__(self, context_path: str):\n",
    "        # Wrap OpenAI client with Openlayer's OpenAIMonitor to trace it \n",
    "        self.openai_client = OpenAI()\n",
    "        llm_monitors.OpenAIMonitor(client=self.openai_client)\n",
    "        \n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        with open(context_path, 'r', encoding='utf-8') as file:\n",
    "            self.context_sections = file.read().split('\\n\\n')  \n",
    "        self.tfidf_matrix = self.vectorizer.fit_transform(self.context_sections)\n",
    "\n",
    "    # Decorate the functions you'd like to trace with @tracer.trace()\n",
    "    @tracer.trace()\n",
    "    def query(self, user_query: str) -> str:\n",
    "        \"\"\"Main method.\n",
    "\n",
    "        Answers to a user query with the LLM.\n",
    "        \"\"\"\n",
    "        context = self.retrieve_context(user_query)\n",
    "        prompt = self.inject_prompt(user_query, context)\n",
    "        answer = self.generate_answer_with_gpt(prompt)\n",
    "        return answer\n",
    "\n",
    "    @tracer.trace()\n",
    "    def retrieve_context(self, query: str) -> str:\n",
    "        \"\"\"Context retriever. \n",
    "        \n",
    "        Given the query, returns the most similar context (using TFIDF).\n",
    "        \"\"\"\n",
    "        query_vector = self.vectorizer.transform([query])\n",
    "        cosine_similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()\n",
    "        most_relevant_idx = np.argmax(cosine_similarities)\n",
    "        return self.context_sections[most_relevant_idx]\n",
    "\n",
    "    @tracer.trace()\n",
    "    def inject_prompt(self, query: str, context: str):\n",
    "        \"\"\"Combines the query with the context and returns\n",
    "        the prompt (formatted to conform with OpenAI models).\"\"\"\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Answer the user query using only the following context: {context}. \\nUser query: {query}\"}\n",
    "        ]\n",
    "\n",
    "    @tracer.trace()\n",
    "    def generate_answer_with_gpt(self, prompt):\n",
    "        \"\"\"Forwards the prompt to GPT and returns the answer.\"\"\"\n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            messages=prompt,\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96f7073-7be4-4254-a6c9-eb808312beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = RagPipeline(\"context.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e046fd-68f1-4f66-b2a1-03aa95b9b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.query(\"Who were the founders of Apple?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7f963-fc13-4e93-b3ef-98aa183770a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.query(\"When did Apple IPO?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f1e832-4c3f-4a6a-8013-8607ff141f67",
   "metadata": {},
   "source": [
    "That's it! After each inference, the traces are uploaded to Openlayer. If you navigate to your project, you should see the traces for these two inferences with our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960a36f-3438-4c81-8cdb-ca078aa509cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
