{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef55abc9",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openlayer-ai/examples-gallery/blob/main/monitoring/quickstart/monitoring-quickstart.ipynb)\n",
    "\n",
    "\n",
    "# <a id=\"top\">Monitoring quickstart</a>\n",
    "\n",
    "This notebook illustrates a typical monitoring flow using Openlayer.\n",
    "\n",
    "\n",
    "## <a id=\"toc\">Table of contents</a>\n",
    "\n",
    "1. [**Creating a project and an inference pipeline**](#inference-pipeline)   \n",
    "\n",
    "2. [**Uploading a reference dataset**](#reference-dataset)\n",
    "\n",
    "3. [**Publishing batches of production data**](#publish-batches)\n",
    "\n",
    "\n",
    "4. [**Publishing ground truths**](#ground-truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea849d",
   "metadata": {},
   "source": [
    "## <a id=\"inference-pipeline\"> 1. Creating a project and an inference pipeline </a>\n",
    "\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f27b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openlayer\n",
    "from openlayer.tasks import TaskType\n",
    "\n",
    "client = openlayer.OpenlayerClient(\"YOUR_API_KEY_HERE\")\n",
    "project = client.create_or_load_project(\n",
    "    name=\"Churn Prediction \",\n",
    "    task_type=TaskType.TabularClassification,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0c9bf6",
   "metadata": {},
   "source": [
    "Now that you are authenticated and have a project on the platform, it's time to create an inference pipeline. Creating an inference pipeline is what enables the monitoring capabilities in a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b5294",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline = project.create_inference_pipeline()\n",
    "\n",
    "# Or \n",
    "# inference_pipeline = project.load_inference_pipeline(name=\"Production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39592b32",
   "metadata": {},
   "source": [
    "## <a id=\"reference-dataset\"> 2. Uploading a reference dataset </a>\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "A reference dataset is optional, but it enables drift monitoring. Ideally, the reference dataset is a representative sample of the training set used to train the deployed model. In this section, we first load the dataset and then we upload it to Openlayer using the `upload_reference_dataframe` method.\n",
    "\n",
    "### <a id=\"download-reference\"> Downloading the data </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5be714",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -e \"churn_train.csv\" ]; then\n",
    "    curl \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/monitoring/churn_train.csv\" --output \"churn_train.csv\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31809ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_set = pd.read_csv(\"./churn_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6336802",
   "metadata": {},
   "source": [
    "### <a id=\"upload-reference\"> Uploading the dataset to Openlayer </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8e23e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "    \"categoricalFeatureNames\": [\"Gender\", \"Geography\"],\n",
    "    \"classNames\": [\"Retained\", \"Exited\"],\n",
    "        \"featureNames\": [\n",
    "        \"CreditScore\", \n",
    "        \"Geography\",\n",
    "        \"Gender\",\n",
    "        \"Age\", \n",
    "        \"Tenure\",\n",
    "        \"Balance\",\n",
    "        \"NumOfProducts\",\n",
    "        \"HasCrCard\",\n",
    "        \"IsActiveMember\",\n",
    "        \"EstimatedSalary\",\n",
    "        \"AggregateRate\",\n",
    "        \"Year\"\n",
    "    ],\n",
    "    \"labelColumnName\": \"Exited\",\n",
    "    \"label\": \"training\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline.upload_reference_dataframe(\n",
    "    dataset_df=training_set,\n",
    "    dataset_config=dataset_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8608ea",
   "metadata": {},
   "source": [
    "## <a id=\"publish-batches\"> 3. Publishing batches of data </a>\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "In production, as the model makes predictions, the data can be published to Openlayer. This is done with the `publish_batch_data` method. \n",
    "\n",
    "The data published to Openlayer can have a column with **inference ids** and another with **timestamps** (UNIX ms format). These are both optional and, if not provided, will receive default values. The inference id is particularly important if you wish to publish ground truths at a later time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83afd5b",
   "metadata": {},
   "source": [
    "### <a id=\"download-batches\"> Download the data </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a5462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -e \"prod_data_no_ground_truths.csv\" ]; then\n",
    "    curl \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/monitoring/prod_data_no_ground_truths.csv\" --output \"prod_data_no_ground_truths.csv\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918da1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "production_data = pd.read_csv(\"prod_data_no_ground_truths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deec9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = production_data.loc[:342]\n",
    "batch_2 = production_data.loc[342:684]\n",
    "batch_3 = production_data.loc[684:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc126446",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf399a",
   "metadata": {},
   "source": [
    "### <a id=\"publish-batches\"> Publish to Openlayer </a>\n",
    "\n",
    "Here, we're simulating three calls to `publish_batch_data`. In practice, this is a code snippet that lives in your inference pipeline and that gets called after the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_config = {\n",
    "    \"categoricalFeatureNames\": [\"Gender\", \"Geography\"],\n",
    "    \"classNames\": [\"Retained\", \"Exited\"],\n",
    "    \"featureNames\": [\n",
    "        \"CreditScore\", \n",
    "        \"Geography\",\n",
    "        \"Gender\",\n",
    "        \"Age\", \n",
    "        \"Tenure\",\n",
    "        \"Balance\",\n",
    "        \"NumOfProducts\",\n",
    "        \"HasCrCard\",\n",
    "        \"IsActiveMember\",\n",
    "        \"EstimatedSalary\",\n",
    "        \"AggregateRate\",\n",
    "        \"Year\"\n",
    "    ],\n",
    "    \"timestampColumnName\": \"timestamp\",\n",
    "    \"inferenceIdColumnName\": \"inference_id\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde01a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline.publish_batch_data(\n",
    "    batch_df=batch_1,\n",
    "    batch_config=batch_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc3dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline.publish_batch_data(\n",
    "    batch_df=batch_2,\n",
    "    batch_config=batch_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline.publish_batch_data(\n",
    "    batch_df=batch_3,\n",
    "    batch_config=batch_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc1fca3",
   "metadata": {},
   "source": [
    "## <a id=\"ground-truths\"> 4. Publishing ground truths for past batches </a>\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "The `publish_ground_truths` method can be used to update the ground truths for batches of data already published to the Openlayer platform. The inference id is what gets used to merge the ground truths with the corresponding rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc9594",
   "metadata": {},
   "source": [
    "### <a id=\"download-truth\"> Download the data </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -e \"prod_ground_truths.csv\" ]; then\n",
    "    curl \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/monitoring/prod_ground_truths.csv\" --output \"prod_ground_truths.csv\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03355dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truths = pd.read_csv(\"prod_ground_truths.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903480c8",
   "metadata": {},
   "source": [
    "### <a id=\"publish-truth\">Publish ground truths </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd906c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline.publish_ground_truths(\n",
    "    df=ground_truths,\n",
    "    ground_truth_column_name=\"Exited\",\n",
    "    inference_id_column_name=\"inference_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3749495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
