{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "201fd2a7",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openlayer-ai/examples-gallery/blob/main/development/llms/langchain/question-answering-with-context/web_retrieval.ipynb)\n",
                "\n",
                "\n",
                "# <a id=\"top\">Using a LangChain chain to retrieve information from Wikipedia</a>\n",
                "\n",
                "This notebook illustrates how a LangChain chain that retrieves information from Wikipedia to answer questions can be uploaded to the Openlayer platform.\n",
                "\n",
                "## <a id=\"toc\">Table of contents</a>\n",
                "\n",
                "1. [**Problem statement**](#problem) \n",
                "\n",
                "2. [**Constructing the chain**](#chain)\n",
                "\n",
                "3. [**Constructing the dataset**](#dataset-output)\n",
                "\n",
                "2. [**Uploading to the Openlayer platform**](#upload)\n",
                "    - [Instantiating the client](#client)\n",
                "    - [Creating a project](#project)\n",
                "    - [Uploading datasets](#dataset)\n",
                "    - [Uploading models](#model)\n",
                "    - [Committing and pushing to the platform](#commit)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3392560d",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "\n",
                "if [ ! -e \"requirements.txt\" ]; then\n",
                "    curl \"https://raw.githubusercontent.com/openlayer-ai/examples-gallery/main/development/llms/langchain/question-answering-with-context/requirements.txt\" --output \"requirements.txt\"\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4f96bd2f",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2378ad39",
            "metadata": {},
            "source": [
                "## <a id=\"problem\">1. Problem statement </a>\n",
                "\n",
                "[Back to top](#top)\n",
                "\n",
                "\n",
                "In this notebook, we will create a LangChain chain that retrieves relevant context from a Wikepedia article to answer questions.\n",
                "\n",
                "Then, we will use it to construct a dataset, and, finally, upload it to the Openlayer platform to evaluate the LLM's performance."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9502aa83",
            "metadata": {},
            "source": [
                "## <a id=\"chain\">2. Constructing a web retrieval class </a>\n",
                "\n",
                "[Back to top](#top)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ba7bafda",
            "metadata": {},
            "source": [
                "### Imports and OpenAI setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6f25e3ae",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "\n",
                "from langchain.chains import RetrievalQA\n",
                "from langchain.chat_models import ChatOpenAI\n",
                "from langchain.document_loaders.web_base import WebBaseLoader\n",
                "from langchain.indexes import VectorstoreIndexCreator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "128977ee-fc05-4581-835e-edcef6b4af3f",
            "metadata": {},
            "outputs": [],
            "source": [
                "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY_HERE\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8dfefad8",
            "metadata": {},
            "source": [
                "### Defining the class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "848bc0ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import Dict\n",
                "\n",
                "\n",
                "class BasicLangChainWebReader:\n",
                "    \"\"\"\n",
                "    Read web content and process the text for conversational purposes.\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, url: str):\n",
                "        \"\"\"\n",
                "        Initialize the reader with a URL.\n",
                "        \"\"\"\n",
                "        self.url = url\n",
                "        vectorstore = self._get_vectorstore_from_url()\n",
                "        self.qa_chain = self._get_qa_chain(vectorstore)\n",
                "\n",
                "    def ask(self, query: str) -> Dict[str, str]:\n",
                "        \"\"\"\n",
                "        Ask a question related to the content of the web page.\n",
                "        \"\"\"\n",
                "        result = self.qa_chain({\"query\": query})\n",
                "        answer = result.get(\"result\")\n",
                "        contexts = []\n",
                "        for document in result[\"source_documents\"]:\n",
                "            if isinstance(document, dict):\n",
                "                contexts.append(document[\"page_content\"])\n",
                "            else:\n",
                "                contexts.append(document.page_content)\n",
                "        \n",
                "        return {\n",
                "            \"answer\": answer,\n",
                "            \"context\": contexts\n",
                "        }\n",
                "\n",
                "    def _get_vectorstore_from_url(self):\n",
                "        \"\"\"\n",
                "        Load the web page and create a vectorstore index.\n",
                "        \"\"\"\n",
                "        loader = WebBaseLoader([self.url])\n",
                "        index = VectorstoreIndexCreator().from_loaders([loader])\n",
                "        return index.vectorstore\n",
                "\n",
                "    def _get_qa_chain(self, vectorstore):\n",
                "        \"\"\"\n",
                "        Create a QA chain from the vector store.\n",
                "        \"\"\"\n",
                "        llm = ChatOpenAI()\n",
                "        return RetrievalQA.from_chain_type(\n",
                "            llm, retriever=vectorstore.as_retriever(), return_source_documents=True\n",
                "        )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "39386384",
            "metadata": {},
            "source": [
                "### Using the web reader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4d2b33fc",
            "metadata": {},
            "outputs": [],
            "source": [
                "web_reader = BasicLangChainWebReader(\"https://en.wikipedia.org/wiki/Apple_Inc.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "09d7346a-312f-4a73-a52b-83bef029beca",
            "metadata": {},
            "outputs": [],
            "source": [
                "response = web_reader.ask(\"Who are the founders of Apple?\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b576237d-bac9-4291-8f23-d3fa5f3621c5",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"Answer: {response['answer']} \\n\\nContext: {response['context']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "121f31f1",
            "metadata": {},
            "source": [
                "## <a id=\"dataset-output\">3. Constructing the dataset </a>\n",
                "\n",
                "[Back to top](#top)\n",
                "\n",
                "\n",
                "Now, let's say we have a list of questions that our chain can answer. Let's use the chain we created and capture its output to construct a dataset.\n",
                "\n",
                "**This assumes you have a valid OpenAI API key and are willing to use it.** **If you prefer not to make the LLM requests**, you can [skip to this cell and download the resulting dataset with the model outputs if you'd like](#download-model-output)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0eef8d5e",
            "metadata": {},
            "outputs": [],
            "source": [
                "questions_and_answers = [\n",
                "    [\"Who is the founder of Apple?\", \"Steve Jobs, Steve Wozniak, and Ronald Wayne\"],\n",
                "    [\"When was Apple founded?\", \"April 1, 1976\"],\n",
                "    [\"what is Apple's mission?\", \"Apple's mission statement is “to create technology that empowers people and enriches their lives.”\"],\n",
                "    [\"what was apple's first product\", \"The company's first product was the Apple I\"],\n",
                "    [\"When did apple go public\", \"December 12, 1980\"]\n",
                "   ]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "14af9b07-a319-4c3e-82c3-587f105bb113",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = pd.DataFrame(questions_and_answers, columns=['query', 'ground_truth'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5c4476ce-9245-46cf-92ab-bace9587ffe4",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "87eb4f4f-d620-4a97-9750-a5afb9b33f6d",
            "metadata": {},
            "outputs": [],
            "source": [
                "answers_and_contexts = dataset[\"query\"].apply(lambda x: pd.Series(web_reader.ask(x)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "80d7b203-3c09-45c5-a234-7732ab257a0b",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset[\"answer\"] = answers_and_contexts[\"answer\"]\n",
                "dataset[\"context\"] = answers_and_contexts[\"context\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f629b722-d5bc-4775-9fac-69f200cb0d07",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "68218975",
            "metadata": {},
            "source": [
                "<a id=\"download-model-output\">**Run the cell below if you didn't want to make the LLM requests:**</a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "70db060b",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "\n",
                "if [ ! -e \"answers_and_contexts.csv\" ]; then\n",
                "    curl \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/llms/langchain/answers_and_contexts.csv\" --output \"answers_and_contexts.csv\"\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1cfd8873",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = pd.read_csv(\"answers_and_contexts.csv\")\n",
                "\n",
                "dataset.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a872cec1",
            "metadata": {},
            "source": [
                "## <a id=\"upload\">4. Uploading to the Openlayer platform </a>\n",
                "\n",
                "[Back to top](#top)\n",
                "\n",
                "Now it's time to upload the datasets and model to the Openlayer platform."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c625e210",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install openlayer"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5faaa7bd",
            "metadata": {},
            "source": [
                "### <a id=\"client\">Instantiating the client</a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dbf313c9",
            "metadata": {},
            "outputs": [],
            "source": [
                "import openlayer\n",
                "\n",
                "client = openlayer.OpenlayerClient(\"YOUR_API_KEY_HERE\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "214a29b5",
            "metadata": {},
            "source": [
                "### <a id=\"project\">Creating a project on the platform</a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7093d0dc",
            "metadata": {},
            "outputs": [],
            "source": [
                "from openlayer.tasks import TaskType\n",
                "\n",
                "project = client.create_or_load_project(\n",
                "    name=\"Web Retrieval with LangChain\",\n",
                "    task_type=TaskType.LLM,\n",
                "    description=\"Evaluating an LLM that retrieves data from Wikipedia.\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "823818d1",
            "metadata": {},
            "source": [
                "### <a id=\"dataset\">Uploading datasets</a>\n",
                "\n",
                "Before adding the datasets to a project, we need to do Prepare a `dataset_config`.  \n",
                "\n",
                "This is a Python dictionary that contains all the information needed by the Openlayer platform to utilize the dataset. It should include the column names, the input variable names, etc. For details on the `dataset_config` items, see the [API reference](https://reference.openlayer.com/reference/api/openlayer.OpenlayerClient.add_dataset.html#openlayer.OpenlayerClient.add_dataset).\n",
                "\n",
                "Let's prepare the `dataset_config` for our validation set:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e82abd9c",
            "metadata": {},
            "outputs": [],
            "source": [
                "validation_dataset_config = {\n",
                "    \"contextColumnName\": \"context\",\n",
                "    \"questionColumnName\": \"query\",\n",
                "    \"inputVariableNames\": [\"query\", \"context\"],\n",
                "    \"label\": \"validation\",\n",
                "    \"groundTruthColumnName\": \"ground_truth\",\n",
                "    \"outputColumnName\": \"answer\",\n",
                "    \n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aca4615a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validation set\n",
                "project.add_dataframe(\n",
                "    dataset_df=df,\n",
                "    dataset_config=validation_dataset_config,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "099fb391",
            "metadata": {},
            "source": [
                "We can confirm that the validation set is now staged using the `project.status()` method. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "94b41904",
            "metadata": {},
            "outputs": [],
            "source": [
                "project.status()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5289bc72",
            "metadata": {},
            "source": [
                "### <a id=\"model\">Uploading models</a>\n",
                "\n",
                "When it comes to uploading models to the Openlayer platform, there are a few options.\n",
                "\n",
                "In our case, since we're using LangChain, we'll follow the **shell model** route.\n",
                "\n",
                "Shell models are the most straightforward way to get started. They are comprised of metadata and all the analysis is done via their predictions (which are [uploaded with the datasets](#dataset), in the `outputColumnName`).\n",
                "\n",
                "To upload a shell model, we only need to prepare its `model_config` Python dictionary.\n",
                "\n",
                "Let's create a `model_config` for our model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c3983864",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Note the camelCase for the keys\n",
                "model_config = {\n",
                "    \"inputVariableNames\": [\"query\", \"context\"],\n",
                "    \"modelType\": \"shell\",\n",
                "    \"metadata\": {  # Can add anything here, as long as it is a dict\n",
                "        \"output_parser\": None,\n",
                "        \"vector_db_used\": False,\n",
                "        \"temperature\": 0\n",
                "    }\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f40a1bb1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Adding the model\n",
                "project.add_model(\n",
                "    model_config=model_config\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d220ff0d",
            "metadata": {},
            "source": [
                "We can confirm that both the model and the validation set are now staged using the `project.status()` method. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "28e83471",
            "metadata": {},
            "outputs": [],
            "source": [
                "project.status()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "aebe833d",
            "metadata": {},
            "source": [
                "### <a id=\"commit\"> Committing and pushing to the platform </a>\n",
                "\n",
                "Finally, we can commit the first project version to the platform. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "91fba090",
            "metadata": {},
            "outputs": [],
            "source": [
                "project.commit(\"Initial commit!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f5bfe65a",
            "metadata": {},
            "outputs": [],
            "source": [
                "project.status()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3b65b005",
            "metadata": {},
            "outputs": [],
            "source": [
                "project.push()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3a73a82a",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}