{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "201fd2a7",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openlayer-ai/examples-gallery/blob/main/development/llms/langchain/question-answering/question-answering.ipynb)\n",
                "\n",
                "\n",
                "# <a id=\"top\">Using a LangChain chain to answer Python questions</a>\n",
                "\n",
                "This notebook illustrates how a LangChain chain can be uploaded to the Openlayer platform.\n",
                "\n",
                "## <a id=\"toc\">Table of contents</a>\n",
                "\n",
                "1. [**Problem statement**](#problem) \n",
                "\n",
                "2. [**Constructing the chain**](#chain)\n",
                "\n",
                "3. [**Constructing the dataset**](#dataset-output)\n",
                "\n",
                "2. [**Uploading to the Openlayer platform**](#upload)\n",
                "    - [Instantiating the client](#client)\n",
                "    - [Creating a project](#project)\n",
                "    - [Uploading datasets](#dataset)\n",
                "    - [Uploading models](#model)\n",
                "    - [Committing and pushing to the platform](#commit)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4f96bd2f",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "\n",
                "if [ ! -e \"requirements.txt\" ]; then\n",
                "    curl \"https://raw.githubusercontent.com/openlayer-ai/examples-gallery/main/development/llms/langchain/question-answering/requirements.txt\" --output \"requirements.txt\"\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ae4143fe",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2378ad39",
            "metadata": {},
            "source": [
                "## <a id=\"problem\">1. Problem statement </a>\n",
                "\n",
                "[Back to top](#top)\n",
                "\n",
                "\n",
                "In this notebook, we will create a LangChain chain similar to the one from the [Quickstart](https://python.langchain.com/docs/get_started/quickstart).\n",
                "\n",
                "Then, we will use it to construct a dataset, and, finally, upload it to the Openlayer platform to evaluate the LLM's performance."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9502aa83",
            "metadata": {},
            "source": [
                "## <a id=\"chain\">2. Constructing the chain </a>\n",
                "\n",
                "[Back to top](#top)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ba7bafda",
            "metadata": {},
            "source": [
                "**Defining the LLM:**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6f25e3ae",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.chat_models import ChatOpenAI\n",
                "\n",
                "\n",
                "llm = ChatOpenAI(openai_api_key=\"YOUR_OPENAI_API_KEY_HERE\") "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8dfefad8",
            "metadata": {},
            "source": [
                "**Defining the prompt:**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "848bc0ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.prompts.chat import (\n",
                "    ChatPromptTemplate,\n",
                "    SystemMessagePromptTemplate,\n",
                "    HumanMessagePromptTemplate,\n",
                ")\n",
                "\n",
                "template = \"\"\"You are a helpful assistant who answers user's questions about Python.\n",
                "A user will pass in a question, and you should answer it very objectively.\n",
                "Use AT MOST 5 sentences. If you need more than 5 sentences to answer, say that the\n",
                "user should make their question more objective.\"\"\"\n",
                "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
                "\n",
                "human_template = \"{question}\"\n",
                "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bbd06c94",
            "metadata": {},
            "outputs": [],
            "source": [
                "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "372981f4",
            "metadata": {},
            "source": [
                "**Defining the chain:**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b6e8a220",
            "metadata": {},
            "outputs": [],
            "source": [
                "from langchain.chains import LLMChain\n",
                "\n",
                "chain = LLMChain(\n",
                "    llm=llm,\n",
                "    prompt=chat_prompt,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "39386384",
            "metadata": {},
            "source": [
                "**Using the chain:**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4d2b33fc",
            "metadata": {},
            "outputs": [],
            "source": [
                "chain.run(\"How can I define a class?\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "121f31f1",
            "metadata": {},
            "source": [
                "## <a id=\"dataset-output\">3. Constructing the dataset </a>\n",
                "\n",
                "[Back to top](#top)\n",
                "\n",
                "\n",
                "Now, let's say we have a list of questions that our chain can answer. Let's use the chain we created and capture its output to construct a dataset.\n",
                "\n",
                "**This assumes you have a valid OpenAI API key and are willing to use it.** **If you prefer not to make the LLM requests**, you can [skip to this cell and download the resulting dataset with the model outputs if you'd like](#download-model-output)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0eef8d5e",
            "metadata": {},
            "outputs": [],
            "source": [
                "questions_list = [\n",
                "    \"What is Python and why is it popular?\",\n",
                "    \"How do I write a single-line comment in Python?\",\n",
                "    \"What is the purpose of indentation in Python?\",\n",
                "    \"Can you explain the difference between Python 2 and Python 3?\",\n",
                "    \"What is the Python Standard Library?\",\n",
                "    \"How do I declare a variable in Python?\",\n",
                "    \"What are data types and how do they work in Python?\",\n",
                "    \"How can I convert one data type to another?\",\n",
                "    \"What is the 'print()' function used for?\",\n",
                "    \"How do I get user input in Python?\",\n",
                "    \"What are strings and how can I manipulate them?\",\n",
                "    \"How do I format strings in Python?\",\n",
                "    \"What is a list and how do I create one?\",\n",
                "    \"How do I access elements in a list?\",\n",
                "    \"What is a tuple and how is it different from a list?\",\n",
                "    \"How can I add or remove items from a list?\",\n",
                "    \"What is a dictionary and how can I use it?\",\n",
                "    \"How do I loop through data using 'for' loops?\",\n",
                "    \"What is a 'while' loop and how do I use it?\",\n",
                "    \"How do I write conditional statements in Python?\",\n",
                "    \"What does 'if', 'elif', and 'else' do?\",\n",
                "    \"What is a function and how do I define one?\",\n",
                "    \"How do I call a function?\",\n",
                "    \"What is the return statement in a function?\",\n",
                "    \"How can I reuse code using functions?\",\n",
                "    \"What are modules and how do I use them?\",\n",
                "    \"How can I handle errors and exceptions in Python?\",\n",
                "    \"What is object-oriented programming (OOP)?\",\n",
                "    \"What are classes and objects?\",\n",
                "    \"How can I create and use a class?\",\n",
                "    \"What is inheritance and why is it useful?\",\n",
                "    \"How do I import classes and functions from other files?\",\n",
                "    \"What is the purpose of '__init__()' in a class?\",\n",
                "    \"How can I override methods in a subclass?\",\n",
                "    \"What are instance variables and class variables?\",\n",
                "    \"What is encapsulation in OOP?\",\n",
                "    \"What are getter and setter methods?\",\n",
                "    \"How do I read and write files in Python?\",\n",
                "    \"What is the 'with' statement used for?\",\n",
                "    \"How can I handle CSV and JSON files?\",\n",
                "    \"What is list comprehension?\",\n",
                "    \"How can I sort and filter data in a list?\",\n",
                "    \"What are lambda functions?\",\n",
                "    \"What is the difference between a shallow copy and a deep copy?\",\n",
                "    \"How do I work with dates and times in Python?\",\n",
                "    \"What is recursion and when is it useful?\",\n",
                "    \"How do I install external packages using 'pip'?\",\n",
                "    \"What is a virtual environment and why should I use one?\",\n",
                "    \"How can I work with APIs in Python?\",\n",
                "    \"What are decorators?\",\n",
                "    \"Can you explain the Global Interpreter Lock (GIL)?\"\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d9a12c66",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creating the dataset (a pandas df)\n",
                "import pandas as pd\n",
                "\n",
                "dataset = pd.DataFrame({\"question\": questions_list})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2b0fca46",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "15dc6a57",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using the chain and capturing its output\n",
                "dataset[\"answer\"] = dataset[\"question\"].apply(chain.run)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a1ec1ce7",
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d3cd7569",
            "metadata": {},
            "source": [
                "<a id=\"download-model-output\">**Run the cell below if you didn't want to make the LLM requests:**</a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3fe9f68a",
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "\n",
                "if [ ! -e \"python_questions_and_answers.csv\" ]; then\n",
                "    curl \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/llms/langchain/python_questions_and_answers.csv\" --output \"python_questions_and_answers.csv\"\n",
                "fi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d2d83ec0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "dataset = pd.read_csv(\"python_questions_and_answers.csv\")\n",
                "\n",
                "dataset.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a872cec1",
            "metadata": {},
            "source": [
                "## <a id=\"upload\">4. Uploading to the Openlayer platform </a>\n",
                "\n",
                "[Back to top](#top)\n",
                "\n",
                "Now it's time to upload the datasets and model to the Openlayer platform."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c625e210",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install openlayer"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5faaa7bd",
            "metadata": {},
            "source": [
                "### <a id=\"client\">Instantiating the client</a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dbf313c9",
            "metadata": {},
            "outputs": [],
            "source": [
                "import openlayer\n",
                "\n",
                "client = openlayer.OpenlayerClient(\"YOUR_API_KEY_HERE\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "214a29b5",
            "metadata": {},
            "source": [
                "### <a id=\"project\">Creating a project on the platform</a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7093d0dc",
            "metadata": {},
            "outputs": [],
            "source": [
                "from openlayer.tasks import TaskType\n",
                "\n",
                "project = client.create_or_load_project(\n",
                "    name=\"QA with LangChain\",\n",
                "    task_type=TaskType.LLM,\n",
                "    description=\"Evaluating an LLM that answers Python questions.\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "823818d1",
            "metadata": {},
            "source": [
                "### <a id=\"dataset\">Uploading datasets</a>\n",
                "\n",
                "Before adding the datasets to a project, we need to do Prepare a `dataset_config`.  \n",
                "\n",
                "This is a Python dictionary that contains all the information needed by the Openlayer platform to utilize the dataset. It should include the column names, the input variable names, etc. For details on the `dataset_config` items, see the [API reference](https://reference.openlayer.com/reference/api/openlayer.OpenlayerClient.add_dataset.html#openlayer.OpenlayerClient.add_dataset).\n",
                "\n",
                "Let's prepare the `dataset_config` for our validation set:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6697ffac",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Some variables that will go into the `dataset_config`\n",
                "input_variable_names = [\"question\"]\n",
                "output_column_name = \"answer\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e82abd9c",
            "metadata": {},
            "outputs": [],
            "source": [
                "validation_dataset_config = {\n",
                "    \"inputVariableNames\": input_variable_names,\n",
                "    \"label\": \"validation\",\n",
                "    \"outputColumnName\": output_column_name,\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aca4615a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Validation set\n",
                "project.add_dataframe(\n",
                "    dataset_df=dataset,\n",
                "    dataset_config=validation_dataset_config,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "099fb391",
            "metadata": {},
            "source": [
                "We can confirm that the validation set is now staged using the `project.status()` method. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "94b41904",
            "metadata": {},
            "outputs": [],
            "source": [
                "project.status()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5289bc72",
            "metadata": {},
            "source": [
                "### <a id=\"model\">Uploading models</a>\n",
                "\n",
                "When it comes to uploading models to the Openlayer platform, there are a few options.\n",
                "\n",
                "In our case, since we're using LangChain, we'll follow the **shell model** route.\n",
                "\n",
                "Shell models are the most straightforward way to get started. They are comprised of metadata and all the analysis is done via their predictions (which are [uploaded with the datasets](#dataset), in the `outputColumnName`).\n",
                "\n",
                "To upload a shell model, we only need to prepare its `model_config` Python dictionary.\n",
                "\n",
                "Let's create a `model_config` for our model:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1053c839",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Useful variable that will also go into our config\n",
                "template = \"\"\"You are a helpful assistant who answers user's questions about Python.\n",
                "A user will pass in a question, and you should answer it very objectively.\n",
                "Use AT MOST 5 sentences. If you need more than 5 sentences to answer, say that the\n",
                "user should make their question more objective.\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c3983864",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Note the camelCase for the keys\n",
                "model_config = {\n",
                "    \"inputVariableNames\": [\"question\"],\n",
                "    \"modelType\": \"shell\",\n",
                "    \"prompt\": [ # Optionally log the prompt, following the same format as OpenAI\n",
                "        {\"role\": \"system\", \"content\": template}, \n",
                "        {\"role\": \"user\", \"content\": \"{question}\"}\n",
                "    ], \n",
                "    \"metadata\": {  # Can add anything here, as long as it is a dict\n",
                "        \"output_parser\": None,\n",
                "        \"vector_db_used\": False,\n",
                "        \"temperature\": 0\n",
                "    }\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f40a1bb1",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Adding the model\n",
                "project.add_model(\n",
                "    model_config=model_config\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d220ff0d",
            "metadata": {},
            "source": [
                "We can confirm that both the model and the validation set are now staged using the `project.status()` method. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "28e83471",
            "metadata": {},
            "outputs": [],
            "source": [
                "project.status()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "aebe833d",
            "metadata": {},
            "source": [
                "### <a id=\"commit\"> Committing and pushing to the platform </a>\n",
                "\n",
                "Finally, we can commit the first project version to the platform. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "91fba090",
            "metadata": {},
            "outputs": [],
            "source": [
                "project.commit(\"Initial commit!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f5bfe65a",
            "metadata": {},
            "outputs": [],
            "source": [
                "project.status()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3b65b005",
            "metadata": {},
            "outputs": [],
            "source": [
                "project.push()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3a73a82a",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}