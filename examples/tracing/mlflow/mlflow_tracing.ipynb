{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2722b419",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openlayer-ai/openlayer-python/blob/main/examples/tracing/mlflow/mlflow_tracing.ipynb)\n",
    "\n",
    "\n",
    "# <a id=\"top\">MLflow quickstart</a>\n",
    "\n",
    "This notebook shows how to export traces captured by [MLflow](https://mlflow.org/docs/latest/tracing/integrations/) to Openlayer. The integration is done via the Openlayer's [OpenTelemetry endpoint](https://www.openlayer.com/docs/integrations/opentelemetry). For more information, refer to the [MLflow integration guide](https://www.openlayer.com/docs/integrations/mlflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c8f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c2a473",
   "metadata": {},
   "source": [
    "## 1. Set the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f4fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY_HERE\"\n",
    "\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_TRACES_ENDPOINT\"] = \"https://api.openlayer.com/v1/otel/v1/traces\"\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_TRACES_HEADERS\"] = \"Authorization=Bearer YOUR_OPENLAYER_API_KEY_HERE, x-bt-parent=pipeline_id:YOUR_OPENLAYER_PIPELINE_ID_HERE\"\n",
    "os.environ['OTEL_EXPORTER_OTLP_TRACES_PROTOCOL']= \"http/protobuf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9758533f",
   "metadata": {},
   "source": [
    "## 2. Initialize MLflow instrumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c35d9860-dc41-4f7c-8d69-cc2ac7e5e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.openai.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6b954",
   "metadata": {},
   "source": [
    "## 3. Use LLMs and workflows as usual\n",
    "\n",
    "That's it! Now you can continue using LLMs and workflows as usual.The trace data is automatically exported to Openlayer and you can start creating tests around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00c1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf6987-c257-4f0d-96e7-3739b24c7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": \"How are you doing today?\"}]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openlayer-assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
