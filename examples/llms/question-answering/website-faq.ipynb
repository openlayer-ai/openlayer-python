{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201fd2a7",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openlayer-ai/examples-gallery/blob/main/llms/question-answering/website-faq.ipynb)\n",
    "\n",
    "\n",
    "# <a id=\"top\">Answering questions about a website with LLMs</a>\n",
    "\n",
    "This notebook illustrates how an LLM used for QA can be uploaded to the Openlayer platform.\n",
    "\n",
    "## <a id=\"toc\">Table of contents</a>\n",
    "\n",
    "1. [**Problem statement**](#problem) \n",
    "\n",
    "2. [**Downloading the dataset**](#dataset-download)\n",
    "\n",
    "3. [**Adding the model outputs to the dataset**](#model-output)\n",
    "\n",
    "2. [**Uploading to the Openlayer platform**](#upload)\n",
    "    - [Instantiating the client](#client)\n",
    "    - [Creating a project](#project)\n",
    "    - [Uploading datasets](#dataset)\n",
    "    - [Uploading models](#model)\n",
    "        - [Shell models](#shell)\n",
    "    - [Committing and pushing to the platform](#commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -e \"requirements.txt\" ]; then\n",
    "    curl \"https://raw.githubusercontent.com/openlayer-ai/examples-gallery/main/llms/question-answering/requirements.txt\" --output \"requirements.txt\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4143fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2378ad39",
   "metadata": {},
   "source": [
    "## <a id=\"problem\">1. Problem statement </a>\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "\n",
    "In this notebook, we will use an LLM to answer questions about a crawled website. It illustrates how the [LLM used in OpenAI's tutorial](https://platform.openai.com/docs/tutorials/web-qa-embeddings) can be used with the Openlayer platform.\n",
    "\n",
    "The interested reader is encouraged to follow OpenAI's tutorial using the Embeddings API and then using the crawled website as context for the LLM. Here, we will focus on how such LLM can be uploaded to the Openlayer platform for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d347208a",
   "metadata": {},
   "source": [
    "## <a id=\"dataset-download\">2. Downloading the dataset </a>\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "The dataset we'll use to evaluate the LLM is stored in an S3 bucket. Run the cells below to download it and inspect it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -e \"openai_questions.csv\" ]; then\n",
    "    curl \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/llms/qa/openai_questions.csv\" --output \"openai_questions.csv\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087aa2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca95f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"openai_questions.csv\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b01350a",
   "metadata": {},
   "source": [
    "Our dataset has a single column with questions for the LLM. We will now use the LLM constructed on OpenAI's tutorial to get the answers for each row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdece83",
   "metadata": {},
   "source": [
    "## <a id=\"dataset-download\">3. Adding model outputs to the dataset </a>\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "As mentioned, we now want to add an extra column to our dataset: the `model_output` column with the LLM's prediction for each row.\n",
    "\n",
    "There are many ways to achieve this goal. Here, we will assume that you have run the LLM the same way OpenAI outlines in their tutorial, which the [code can be found here](https://github.com/openai/openai-cookbook/blob/c651bfdda64ac049747c2a174cde1c946e2baf1d/apps/web-crawl-q-and-a/web-qa.ipynb).\n",
    "\n",
    "Run the cell below to download the dataset with the extra `answer` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -e \"openai_questions_and_answers.csv\" ]; then\n",
    "    curl \"https://openlayer-static-assets.s3.us-west-2.amazonaws.com/examples-datasets/llms/qa/openai_questions_and_answers.csv\" --output \"openai_questions_and_answers.csv\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d83ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"openai_questions_and_answers.csv\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872cec1",
   "metadata": {},
   "source": [
    "## <a id=\"upload\">4. Uploading to the Openlayer platform </a>\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "Now it's time to upload the datasets and model to the Openlayer platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faaa7bd",
   "metadata": {},
   "source": [
    "### <a id=\"client\">Instantiating the client</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf313c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openlayer\n",
    "\n",
    "client = openlayer.OpenlayerClient(\"YOUR_API_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a29b5",
   "metadata": {},
   "source": [
    "### <a id=\"project\">Creating a project on the platform</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7093d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openlayer.tasks import TaskType\n",
    "\n",
    "project = client.create_or_load_project(\n",
    "    name=\"QA with LLMs\",\n",
    "    task_type=TaskType.LLMQuestionAnswering,\n",
    "    description=\"Evaluating an LLM used for QA.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823818d1",
   "metadata": {},
   "source": [
    "### <a id=\"dataset\">Uploading datasets</a>\n",
    "\n",
    "Before adding the datasets to a project, we need to do Prepare a `dataset_config`.  \n",
    "\n",
    "This is a Python dictionary that contains all the information needed by the Openlayer platform to utilize the dataset. It should include the column names, the input variable names, etc. For details on the `dataset_config` items, see the [API reference](https://reference.openlayer.com/reference/api/openlayer.OpenlayerClient.add_dataset.html#openlayer.OpenlayerClient.add_dataset).\n",
    "\n",
    "Let's prepare the `dataset_config` for our validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697ffac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some variables that will go into the `dataset_config`\n",
    "input_variable_names = [\"questions\"]\n",
    "output_column_name = \"answers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82abd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset_config = {\n",
    "    \"inputVariableNames\": input_variable_names,\n",
    "    \"label\": \"validation\",\n",
    "    \"outputColumnName\": output_column_name,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "project.add_dataframe(\n",
    "    dataset_df=dataset,\n",
    "    dataset_config=validation_dataset_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099fb391",
   "metadata": {},
   "source": [
    "We can confirm that the validation set is now staged using the `project.status()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b41904",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5289bc72",
   "metadata": {},
   "source": [
    "### <a id=\"model\">Uploading models</a>\n",
    "\n",
    "When it comes to uploading models to the Openlayer platform, there are a few options:\n",
    "\n",
    "- The first one is to upload a **shell model**. Shell models are the most straightforward way to get started. They are comprised of metadata and all of the analysis are done via their predictions (which are [uploaded with the datasets](#dataset), in the `outputColumnName`).\n",
    "- The second one is to upload a **direct-to-API model**. In this is the analogous case to using one of `openlayer`'s model runners in the notebook environment. By doing, you'll be able to interact with the LLM using the platform's UI and also perform a series of robustness assessments on the model using data that is not in your dataset. \n",
    "\n",
    "\n",
    "In this notebook, we will follow the **shell model** approach. Refer to the other notebooks for direct-to-API examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed5cad",
   "metadata": {},
   "source": [
    "#### <a id=\"shell\"> Shell models </a>\n",
    "\n",
    "To upload a shell model, we only need to prepare its `model_config` Python dictionary.\n",
    "\n",
    "Let's create a `model_config` for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6873fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the camelCase for the keys\n",
    "model_config = {\n",
    "    \"inputVariableNames\": [\"questions\"],\n",
    "    \"modelType\": \"shell\",\n",
    "    \"metadata\": {  # Can add anything here, as long as it is a dict\n",
    "        \"context_used\": True,\n",
    "        \"embedding_db\": False,\n",
    "        \"max_token_sequence\": 150\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the model\n",
    "project.add_model(\n",
    "    model_config=model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d220ff0d",
   "metadata": {},
   "source": [
    "We can confirm that both the model and the validation set are now staged using the `project.status()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e83471",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe833d",
   "metadata": {},
   "source": [
    "### <a id=\"commit\"> Committing and pushing to the platform </a>\n",
    "\n",
    "Finally, we can commit the first project version to the platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fba090",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.commit(\"Initial commit!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfe65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73a82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
